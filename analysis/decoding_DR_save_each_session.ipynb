{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "743f5c21",
   "metadata": {},
   "source": [
    "# Decode stimuli/block/licks from neural activity - DR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d7bb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.signal as sg\n",
    "import scipy.stats as st\n",
    "import xarray as xr\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import ast\n",
    "from sklearn import svm\n",
    "import glob\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from DR_analysis_utils import Session, makePSTH, make_neuron_time_trials_tensor, compute_smoothed_response_rate\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95638ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set paths to experiment folders\n",
    "main_path = [\n",
    "    r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\PilotEphys\\Task 2 pilot\\DRpilot_626791_20220815\\processed\",\n",
    "    r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\PilotEphys\\Task 2 pilot\\DRpilot_626791_20220816\\processed\",\n",
    "    r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\PilotEphys\\Task 2 pilot\\DRpilot_626791_20220817\\processed\",\n",
    "    r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\PilotEphys\\Task 2 pilot\\DRpilot_636766_20230123\\processed\", \n",
    "    r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\PilotEphys\\Task 2 pilot\\DRpilot_636766_20230124\\processed\", \n",
    "    r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\PilotEphys\\Task 2 pilot\\DRpilot_636766_20230125\\processed\", \n",
    "    r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\PilotEphys\\Task 2 pilot\\DRpilot_636766_20230126\\processed\", \n",
    "    r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\PilotEphys\\Task 2 pilot\\DRpilot_644864_20230130\\processed\",\n",
    "    r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\PilotEphys\\Task 2 pilot\\DRpilot_644864_20230131\\processed\", \n",
    "    r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\PilotEphys\\Task 2 pilot\\DRpilot_644864_20230201\\processed\", \n",
    "    r\"\\\\allen\\programs\\mindscope\\workgroups\\np-exp\\PilotEphys\\Task 2 pilot\\DRpilot_644864_20230202\\processed\",\n",
    "#     r\"\\\\allen\\programs\\mindscope\\workgroups\\np-exp\\PilotEphys\\Task 2 pilot\\DRpilot_644866_20230207\\processed\", \n",
    "    r\"Y:\\DRpilot_644866_20230208\\processed\",\n",
    "    r\"Y:\\DRpilot_644866_20230209\\processed\",\n",
    "    r\"Y:\\DRpilot_644866_20230210\\processed\",\n",
    "    r\"Y:\\DRpilot_644867_20230220\\processed\",\n",
    "    r\"Y:\\DRpilot_644867_20230221\\processed\",\n",
    "    r\"Y:\\DRpilot_644867_20230222\\processed\",\n",
    "    r\"Y:\\DRpilot_644867_20230223\\processed\",\n",
    "    r\"Y:\\DRpilot_649943_20230213\\processed\", \n",
    "    r\"Y:\\DRpilot_649943_20230214\\processed\",\n",
    "    r\"Y:\\DRpilot_649943_20230215\\processed\",\n",
    "    r\"Y:\\DRpilot_649943_20230216\\processed\",\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871cdbd9",
   "metadata": {},
   "source": [
    "## loop through experiments, save all relevant info for each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b08753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_decoder(input_data,labels):\n",
    "    \n",
    "    output={}\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    skf = StratifiedKFold(n_splits=5,shuffle=True)\n",
    "    \n",
    "    scaler.fit(sel_data.T)\n",
    "    X = scaler.transform(input_data)\n",
    "    y = labels\n",
    "    \n",
    "    if len(np.unique(labels))>2:\n",
    "        y_dec_func=np.full((len(y),len(np.unique(labels))), fill_value=np.nan)\n",
    "    else:\n",
    "        y_dec_func=np.full(len(y), fill_value=np.nan)\n",
    " \n",
    "    if type(y[0])==bool:\n",
    "        ypred=np.full(len(y), fill_value=False)\n",
    "    elif type(y[0])==str:\n",
    "        ypred=np.full(len(y), fill_value='       ')\n",
    "    else:\n",
    "        ypred=np.full(len(y), fill_value=np.nan)\n",
    "\n",
    "    tidx_used=[]\n",
    "    \n",
    "    coefs=[]\n",
    "    classes=[]\n",
    "#     feature_names=[]\n",
    "    intercept=[]\n",
    "    params=[]\n",
    "\n",
    "    for train,test in skf.split(X, y):\n",
    "        clf=svm.LinearSVC(max_iter=5000)\n",
    "        clf.fit(X[train],y[train])\n",
    "        ypred[test] = clf.predict(X[test])\n",
    "        y_dec_func[test] = clf.decision_function(X[test])\n",
    "        tidx_used.append([test])\n",
    "        coefs.append(clf.coef_)\n",
    "        classes.append(clf.classes_)\n",
    "#         feature_names.append(clf.feature_names_in_)\n",
    "        intercept.append(clf.intercept_)\n",
    "        params.append(clf.get_params())\n",
    "\n",
    "    cr_dict=classification_report(y, ypred, output_dict=True)\n",
    "    cr_df=pd.DataFrame.from_dict(cr_dict)\n",
    "\n",
    "    output['cr']=cr_df\n",
    "    output['pred_label']=ypred\n",
    "    output['true_label']=y\n",
    "    output['trial_sel_idx']=trial_sel\n",
    "    output['trials_used']=tidx_used\n",
    "    output['decision_function']=y_dec_func\n",
    "    output['coefs']=coefs\n",
    "    output['classes']=classes\n",
    "#     output['feature_names']=feature_names\n",
    "    output['intercept']=intercept\n",
    "    output['params']=params\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b067e131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_forest_decoder(input_data,labels):\n",
    "    ### make this and try it!!\n",
    "#     output={}\n",
    "    \n",
    "#     scaler = StandardScaler()\n",
    "#     skf = StratifiedKFold(n_splits=5,shuffle=True)\n",
    "    \n",
    "#     scaler.fit(sel_data.T)\n",
    "#     X = scaler.transform(input_data)\n",
    "#     y = labels\n",
    "    \n",
    "#     if len(np.unique(labels))>2:\n",
    "#         y_dec_func=np.full((len(y),len(np.unique(labels))), fill_value=np.nan)\n",
    "#     else:\n",
    "#         y_dec_func=np.full(len(y), fill_value=np.nan)\n",
    " \n",
    "#     if type(y[0])==bool:\n",
    "#         ypred=np.full(len(y), fill_value=False)\n",
    "#     elif type(y[0])==str:\n",
    "#         ypred=np.full(len(y), fill_value='       ')\n",
    "#     else:\n",
    "#         ypred=np.full(len(y), fill_value=np.nan)\n",
    "\n",
    "#     tidx_used=[]\n",
    "\n",
    "#     for train,test in skf.split(X, y):\n",
    "#         clf=svm.LinearSVC(max_iter=5000)\n",
    "#         clf.fit(X[train],y[train])\n",
    "#         ypred[test] = clf.predict(X[test])\n",
    "#         y_dec_func[test] = clf.decision_function(X[test])\n",
    "#         tidx_used.append([test])\n",
    "\n",
    "#     cr_dict=classification_report(y, ypred, output_dict=True)\n",
    "#     cr_df=pd.DataFrame.from_dict(cr_dict)\n",
    "\n",
    "#     output['cr']=cr_df\n",
    "#     output['pred_label']=ypred\n",
    "#     output['true_label']=y\n",
    "#     output['trial_sel_idx']=trial_sel\n",
    "#     output['trials_used']=tidx_used\n",
    "#     output['decision_function']=y_dec_func\n",
    "    \n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addd8c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_run_speed(session):\n",
    "\n",
    "    binsize=1\n",
    "    speed_bins=np.arange(0,np.ceil(session.trials['avg_run_speed'].max()),binsize)\n",
    "\n",
    "    visblock_run, edges = np.histogram(session.trials.query('trialstimRewarded==\"vis1\"')['avg_run_speed'],bins=speed_bins)\n",
    "    audblock_run, edges = np.histogram(session.trials.query('trialstimRewarded==\"sound1\"')['avg_run_speed'],bins=speed_bins)\n",
    "\n",
    "    choose_trials=[]\n",
    "\n",
    "    for ib,bb in enumerate(edges[:-1]):\n",
    "\n",
    "        n_chosen_trials = np.min([visblock_run[ib],audblock_run[ib]])\n",
    "\n",
    "        visblock_trials = session.trials.query('trialstimRewarded==\"vis1\" and \\\n",
    "                                                avg_run_speed>=@speed_bins[@ib] and \\\n",
    "                                                avg_run_speed<@speed_bins[@ib+1]').index\n",
    "\n",
    "        audblock_trials = session.trials.query('trialstimRewarded==\"sound1\" and \\\n",
    "                                                avg_run_speed>=@speed_bins[@ib] and \\\n",
    "                                                avg_run_speed<@speed_bins[@ib+1]').index\n",
    "\n",
    "        choose_trials.append(np.random.choice(visblock_trials,n_chosen_trials,replace=False))\n",
    "        choose_trials.append(np.random.choice(audblock_trials,n_chosen_trials,replace=False))\n",
    "\n",
    "\n",
    "    choose_trials = np.sort(np.hstack(choose_trials))\n",
    "    \n",
    "    return choose_trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9129821",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trnum='all'\n",
    "u_num='all'\n",
    "u_min=20\n",
    "n_repeats=1\n",
    "binsize=0.2\n",
    "time_bins=np.arange(-4,3,binsize)\n",
    "balance_labels=0\n",
    "\n",
    "\n",
    "# svc_results={}\n",
    "\n",
    "for sel_session, path in enumerate(main_path[:]):\n",
    "    \n",
    "    svc_results={}\n",
    "    \n",
    "    session=[]\n",
    "    session=Session(path=path) \n",
    "    session.assign_unit_areas()\n",
    "    session=compute_smoothed_response_rate(session)\n",
    "    \n",
    "    # loop through sessions and make unit xarrays\n",
    "    time_before_flash = 4\n",
    "    trial_duration = 7\n",
    "    bin_size = 0.02\n",
    "\n",
    "    # Make tensor (3-D matrix [units,time,trials])\n",
    "    trial_tensor = make_neuron_time_trials_tensor(session.good_units, session.spike_times, \n",
    "                                                  session.trials,time_before_flash, trial_duration, \n",
    "                                                  bin_size)\n",
    "    # make xarray\n",
    "    session.trial_da = xr.DataArray(trial_tensor, dims=(\"unit_id\", \"time\", \"trials\"), \n",
    "                               coords={\n",
    "                                   \"unit_id\": session.good_units.index.values,\n",
    "                                   \"time\": np.arange(0, trial_duration, bin_size)-time_before_flash,\n",
    "                                   \"trials\": session.trials.index.values\n",
    "                                   })\n",
    "    \n",
    "    #shorten the area names to better lump together units\n",
    "    #get rid of layers and/or sub-areas with dashes\n",
    "    area_short = []\n",
    "    for area in session.good_units['area']:\n",
    "        if area=='N/A':\n",
    "            short='N/A'\n",
    "        elif area[:2]=='CA':\n",
    "            short=area\n",
    "        else:\n",
    "            dig_ind=re.search(r\"\\d\", area)\n",
    "            dash_ind=re.search(r\"-\", area)\n",
    "            if dig_ind!=None:\n",
    "                short=area[:dig_ind.start()]\n",
    "            elif dash_ind!=None:\n",
    "                short=area[:dash_ind.start()]\n",
    "            else:\n",
    "                short=area\n",
    "        area_short.append(short)\n",
    "    session.good_units['area_short']=area_short\n",
    "    area_counts=session.good_units['area_short'].value_counts()\n",
    "    \n",
    "#     predict=['stim_ids','block_ids','trial_response']\n",
    "    predict=['block_ids']\n",
    "\n",
    "    #save metadata about this session & decoder params\n",
    "    svc_results['metadata']=session.metadata\n",
    "    svc_results['trial_numbers']=trnum\n",
    "    svc_results['unit_numbers']=u_num\n",
    "    svc_results['min_n_units']=u_min\n",
    "    svc_results['n_repeats']=n_repeats\n",
    "    svc_results['time_bins']=time_bins\n",
    "    svc_results['balance_labels']=balance_labels\n",
    "    \n",
    "    #loop through different labels to predict\n",
    "    for p in predict:\n",
    "        svc_results[p]={}\n",
    "    \n",
    "        #choose what variable to predict\n",
    "        if p=='stim_ids':\n",
    "            #exclude any trials that had opto stimulation\n",
    "            if 'trialOptoVoltage' in session.trials.columns:\n",
    "                trial_sel = session.trials.query('trialOptoVoltage.isnull() and trialStimID != \"catch\"').index\n",
    "            else:\n",
    "                trial_sel = session.trials.query('trialStimID != \"catch\"').index\n",
    "                \n",
    "            # grab the stimulus ids\n",
    "            pred_var = session.trials['trialStimID'][trial_sel].values\n",
    "    \n",
    "        elif p=='block_ids':\n",
    "            #exclude any trials that had opto stimulation\n",
    "            if 'trialOptoVoltage' in session.trials.columns:\n",
    "                trial_sel = session.trials.query('trialOptoVoltage.isnull()').index\n",
    "            else:\n",
    "                trial_sel = session.trials.index\n",
    "                \n",
    "            # or, use block IDs\n",
    "            pred_var = session.trials['trialstimRewarded'][trial_sel].values\n",
    "    \n",
    "        elif p=='trial_response':\n",
    "            #exclude any trials that had opto stimulation\n",
    "            if 'trialOptoVoltage' in session.trials.columns:\n",
    "                trial_sel = session.trials.query('trialOptoVoltage.isnull()').index\n",
    "            else:\n",
    "                trial_sel = session.trials.index\n",
    "                \n",
    "            #or, use whether mouse responded\n",
    "            pred_var = session.trials['trial_response'][trial_sel].values\n",
    "\n",
    "#         area_sel = area_counts[area_counts>=u_min].index\n",
    "#         area_sel = ['all']\n",
    "        area_sel = ['all']+list(area_counts[area_counts>=u_min].index)\n",
    "        \n",
    "        #loop through areas\n",
    "        for aa in area_sel:\n",
    "            if aa=='all':\n",
    "                unit_sel = session.good_units.index.values\n",
    "            else:\n",
    "                unit_sel = session.good_units.query('area_short==@aa').index.values\n",
    "            svc_results[p][aa]={}\n",
    "            svc_results[p][aa]['n_units']=len(unit_sel)\n",
    "            \n",
    "            #loop through time bins\n",
    "            for tt,t_start in enumerate(time_bins[:-1]):\n",
    "                svc_results[p][aa][tt]={}\n",
    "                \n",
    "                #loop through repeats\n",
    "                for nn in range(0,n_repeats):\n",
    "                    \n",
    "                    if u_num=='all':\n",
    "                        unit_subset = unit_sel #np.random.choice(unit_sel,len(unit_sel),replace=False)\n",
    "                    else:\n",
    "                        unit_subset = np.random.choice(unit_sel,u_num,replace=False)\n",
    "                    \n",
    "                    #option to balance number of labels for training\n",
    "                    if balance_labels:\n",
    "                        subset_ind=[]\n",
    "                        conds = np.unique(pred_var)\n",
    "                        cond_count=[]\n",
    "\n",
    "                        if trnum=='all':\n",
    "                            for cc in conds:\n",
    "                                cond_count.append(np.sum(pred_var==cc))\n",
    "                            use_trnum=np.min(cond_count)\n",
    "                        else:\n",
    "                            use_trnum = trnum\n",
    "\n",
    "                        for cc in conds:\n",
    "                            cond_inds=np.where(pred_var==cc)[0]\n",
    "                            if len(cond_inds)<use_trnum:\n",
    "                                use_trnum=len(cond_inds)\n",
    "                            subset_ind.append(np.random.choice(cond_inds,use_trnum,replace=False))   \n",
    "                        subset_ind=np.sort(np.hstack(subset_ind))\n",
    "\n",
    "#                         trial_sel=trial_sel[subset_ind]\n",
    "#                         pred_var=pred_var[subset_ind]\n",
    "                    else:\n",
    "                        subset_ind=np.arange(0,len(trial_sel))\n",
    "\n",
    "\n",
    "                    sel_data = session.trial_da.sel(time=slice(t_start,time_bins[tt+1]),\n",
    "                                                    trials=trial_sel[subset_ind],\n",
    "                                                    unit_id=unit_subset).mean(dim='time').values\n",
    "\n",
    "                    svc_results[p][aa][tt][nn]=custom_decoder(\n",
    "                        input_data=sel_data.T,\n",
    "                        labels=pred_var[subset_ind].flatten())\n",
    "\n",
    "                    svc_results[p][aa][tt][nn]['shuffle']=custom_decoder(\n",
    "                        input_data=sel_data.T,\n",
    "                        labels=np.random.choice(pred_var[subset_ind],len(pred_var),replace=False).flatten())\n",
    "\n",
    "                    svc_results[p][aa][tt][nn]['trial_sel_idx']=trial_sel\n",
    "                    svc_results[p][aa][tt][nn]['unit_sel_idx']=unit_subset\n",
    "                    \n",
    "\n",
    "            print(aa+' done')\n",
    "            \n",
    "    print(path+' done')\n",
    "    \n",
    "            \n",
    "    savepath=r'C:\\Users\\ethan.mcbride\\OneDrive - Allen Institute\\DR decoding results\\by_session\\pre_post_stim_activity_all_units'\n",
    "\n",
    "    with open(os.path.join(savepath,session.metadata['mouseID']+'_'+str(session.metadata['ephys_session_num'])+\n",
    "                           'decoder_results_200ms_incl_pre_post_all_units.pkl'), 'wb') as handle:\n",
    "        pickle.dump(svc_results, handle, protocol=pickle.HIGHEST_PROTOCOL)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f55c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_results[p][aa][tt][nn]=custom_decoder(\n",
    "                        input_data=sel_data.T,\n",
    "                        labels=pred_var[subset_ind].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e795e822",
   "metadata": {},
   "outputs": [],
   "source": [
    "['all']+list(area_counts[area_counts>=u_min].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d8de7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_results[p][aa][tt][nn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e71a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax=plt.subplots()\n",
    "# ax.axhline(0,color='k')\n",
    "# ax.plot(svc_results['block_ids']['MOs'][0][nn]['decision_function'])\n",
    "cond_inds.shape\n",
    "use_trnum\n",
    "np.random.choice(cond_inds,use_trnum,replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cb6abe",
   "metadata": {},
   "source": [
    "## balance for running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d168bf13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# balance for running\n",
    "trnum='all'\n",
    "u_num='all'\n",
    "u_min=20\n",
    "n_repeats=20\n",
    "binsize=0.2\n",
    "time_bins=np.arange(-0.2,0.6,binsize)\n",
    "balance_labels=0\n",
    "balance_running=0\n",
    "\n",
    "# svc_results={}\n",
    "\n",
    "for sel_session, path in enumerate(main_path):\n",
    "    \n",
    "    svc_results={}\n",
    "    \n",
    "    session=[]\n",
    "    session=Session(path=path) \n",
    "    session.assign_unit_areas()\n",
    "    session=compute_smoothed_response_rate(session)\n",
    "    \n",
    "    # loop through sessions and make unit xarrays\n",
    "    time_before_flash = 0.25\n",
    "    trial_duration = 1.0\n",
    "    bin_size = 0.001\n",
    "\n",
    "    # Make tensor (3-D matrix [units,time,trials])\n",
    "    trial_tensor = make_neuron_time_trials_tensor(session.good_units, session.spike_times, \n",
    "                                                  session.trials,time_before_flash, trial_duration, \n",
    "                                                  bin_size)\n",
    "    # make xarray\n",
    "    session.trial_da = xr.DataArray(trial_tensor, dims=(\"unit_id\", \"time\", \"trials\"), \n",
    "                               coords={\n",
    "                                   \"unit_id\": session.good_units.index.values,\n",
    "                                   \"time\": np.arange(0, trial_duration, bin_size)-time_before_flash,\n",
    "                                   \"trials\": session.trials.index.values\n",
    "                                   })\n",
    "    \n",
    "    #shorten the area names to better lump together units\n",
    "    #get rid of layers and/or sub-areas with dashes\n",
    "    area_short = []\n",
    "    for area in session.good_units['area']:\n",
    "        if area=='N/A':\n",
    "            short='N/A'\n",
    "        elif area[:2]=='CA':\n",
    "            short=area\n",
    "        else:\n",
    "            dig_ind=re.search(r\"\\d\", area)\n",
    "            dash_ind=re.search(r\"-\", area)\n",
    "            if dig_ind!=None:\n",
    "                short=area[:dig_ind.start()]\n",
    "            elif dash_ind!=None:\n",
    "                short=area[:dash_ind.start()]\n",
    "            else:\n",
    "                short=area\n",
    "        area_short.append(short)\n",
    "    session.good_units['area_short']=area_short\n",
    "    area_counts=session.good_units['area_short'].value_counts()\n",
    "\n",
    "    #exclude any trials that had opto stimulation\n",
    "    if 'trialOptoVoltage' in session.trials.columns:\n",
    "        trial_sel = session.trials.query('trialOptoVoltage.isnull()').index\n",
    "    else:\n",
    "        trial_sel = session.trials.index\n",
    "            \n",
    "    if balance_running:\n",
    "        run_trial_sel = match_run_speed(session)\n",
    "        \n",
    "    predict=['stim_ids','block_ids','trial_response']\n",
    "\n",
    "    # grab the stimulus ids\n",
    "    stim_ids = session.trials['trialStimID'][trial_sel].values\n",
    "    # or, use block IDs\n",
    "    block_ids = session.trials['trialstimRewarded'][trial_sel].values\n",
    "    #or, use whether mouse responded\n",
    "    trial_response = session.trials['trial_response'][trial_sel].values\n",
    "    \n",
    "    #save metadata about this session & decoder params\n",
    "    svc_results['metadata']=session.metadata\n",
    "    svc_results['trial_numbers']=trnum\n",
    "    svc_results['unit_numbers']=u_num\n",
    "    svc_results['min_n_units']=u_min\n",
    "    svc_results['n_repeats']=n_repeats\n",
    "    svc_results['time_bins']=time_bins\n",
    "    svc_results['balance_labels']=balance_labels\n",
    "    \n",
    "    #loop through different labels to predict\n",
    "    for p in predict:\n",
    "        svc_results[p]={}\n",
    "    \n",
    "        #choose what variable to predict\n",
    "        if p=='stim_ids':\n",
    "            pred_var = stim_ids\n",
    "        elif p=='block_ids':\n",
    "            pred_var = block_ids\n",
    "        elif p=='trial_response':\n",
    "            pred_var = trial_response\n",
    "            \n",
    "        if balance_running:\n",
    "            if p=='stim_ids':\n",
    "                run_pred_var = session.trials['trialStimID'][run_trial_sel].values\n",
    "            elif p=='block_ids':\n",
    "                run_pred_var = session.trials['trialstimRewarded'][run_trial_sel].values\n",
    "            elif p=='trial_response':\n",
    "                run_pred_var = session.trials['trial_response'][run_trial_sel].values\n",
    "\n",
    "        area_sel = area_counts[area_counts>=u_min].index\n",
    "        # area_sel = ['all']\n",
    "        \n",
    "        #loop through areas\n",
    "        for aa in area_sel:\n",
    "            if aa=='all':\n",
    "                unit_sel = session.good_units.index.values\n",
    "            else:\n",
    "                unit_sel = session.good_units.query('area_short==@aa').index.values\n",
    "            svc_results[p][aa]={}\n",
    "            svc_results[p][aa]['n_units']=len(unit_sel)\n",
    "            \n",
    "            #loop through time bins\n",
    "            for tt,t_start in enumerate(time_bins[:-1]):\n",
    "                svc_results[p][aa][tt]={}\n",
    "                \n",
    "                #loop through repeats\n",
    "                for nn in range(0,n_repeats):\n",
    "                    \n",
    "                    if u_num=='all':\n",
    "                        unit_subset = np.random.choice(unit_sel,len(unit_sel),replace=False)\n",
    "                    else:\n",
    "                        unit_subset = np.random.choice(unit_sel,u_num,replace=False)\n",
    "                    \n",
    "#                     #option to balance number of labels for training\n",
    "####### need to fix this! potnetially sub-selecting pred_var too much!\n",
    "#                     if balance_labels:\n",
    "#                         subset_ind=[]\n",
    "#                         conds = np.unique(pred_var)\n",
    "#                         cond_count=[]\n",
    "\n",
    "#                         if trnum=='all':\n",
    "#                             for cc in conds:\n",
    "#                                 cond_count.append(np.sum(pred_var==cc))\n",
    "#                             use_trnum=np.min(cond_count)\n",
    "#                         else:\n",
    "#                             use_trnum = trnum\n",
    "\n",
    "#                         for cc in conds:\n",
    "#                             cond_inds=np.where(pred_var==cc)[0]\n",
    "#                             if len(cond_inds)<use_trnum:\n",
    "#                                 use_trnum=len(cond_inds)\n",
    "#                             subset_ind.append(np.random.choice(cond_inds,use_trnum,replace=False))   \n",
    "#                         subset_ind=np.sort(np.hstack(subset_ind))\n",
    "\n",
    "#                         trial_sel=trial_sel[subset_ind]\n",
    "#                         pred_var=pred_var[subset_ind]\n",
    "\n",
    "\n",
    "                    sel_data = session.trial_da.sel(time=slice(t_start,time_bins[tt+1]),\n",
    "                                                    trials=trial_sel,\n",
    "                                                    unit_id=unit_subset).mean(dim='time').values\n",
    "\n",
    "                    svc_results[p][aa][tt][nn]=custom_decoder(\n",
    "                        input_data=sel_data.T,\n",
    "                        labels=pred_var.flatten())\n",
    "                    \n",
    "                    svc_results[p][aa][tt][nn]['trial_sel_idx']=trial_sel\n",
    "                    \n",
    "                    if balance_running:\n",
    "                        \n",
    "                        run_sel_data = session.trial_da.sel(time=slice(t_start,time_bins[tt+1]),\n",
    "                                                    trials=run_trial_sel,\n",
    "                                                    unit_id=unit_subset).mean(dim='time').values\n",
    "                        \n",
    "                        svc_results[p][aa][tt][nn]['balance_running']=custom_decoder(\n",
    "                            input_data=run_sel_data.T,\n",
    "                            labels=run_pred_var.flatten())\n",
    "                        \n",
    "                        svc_results[p][aa][tt][nn]['balance_running']['trial_sel_idx']=run_trial_sel\n",
    "\n",
    "                        \n",
    "            print(aa+' done')\n",
    "            \n",
    "    print(path+' done')\n",
    "    \n",
    "            \n",
    "    savepath=r'C:\\Users\\ethan.mcbride\\OneDrive - Allen Institute\\DR decoding results\\by_session\\balance_running'\n",
    "\n",
    "    with open(os.path.join(savepath,session.metadata['mouseID']+'_'+str(session.metadata['ephys_session_num'])+\n",
    "                           'decoder_results_200ms_balance_running.pkl'), 'wb') as handle:\n",
    "        pickle.dump(svc_results, handle, protocol=pickle.HIGHEST_PROTOCOL)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddc1322",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadpath=r'C:\\Users\\ethan.mcbride\\OneDrive - Allen Institute\\DR decoding results\\by_session\\pre_post_stim_activity'\n",
    "\n",
    "svc_results={}\n",
    "decoder_results=os.listdir(loadpath)\n",
    "\n",
    "for ii,ff in enumerate(decoder_results):\n",
    "    with open(os.path.join(loadpath,ff),'rb') as handle:\n",
    "        svc_results[ii]=pickle.load(handle)\n",
    "    print(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cd05ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all unique areas in results\n",
    "all_areas=[]\n",
    "for sel_session in range(0,len(svc_results)):\n",
    "    all_areas.append(list(svc_results[sel_session]['block_ids'].keys()))\n",
    "    \n",
    "all_areas=np.unique(np.hstack(all_areas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e40985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb65686",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make into more plottable format\n",
    "\n",
    "####change this to deal with multiple #s of trials and average over re-runs of the SVC\n",
    "\n",
    "plot_results={}\n",
    "plot_shuffle_results={}\n",
    "\n",
    "timepoints=time_bins[1:]\n",
    "\n",
    "label_list=['vis1','vis2','sound1','sound2','True','False']\n",
    "# label_list=['vis1','sound1','True','False']\n",
    "\n",
    "# predict=['stim_ids','block_ids','trial_response']\n",
    "predict=['block_ids']\n",
    "\n",
    "# areas=['VISp','AUD','LG','MG','MOs','MRN','CP','MOp']\n",
    "areas=all_areas\n",
    "\n",
    "for sel_session in range(0,len(svc_results)):\n",
    "    plot_results[sel_session]={}\n",
    "    plot_shuffle_results[sel_session]={}\n",
    "    for aa in areas:\n",
    "        plot_results[sel_session][aa]={}\n",
    "        plot_shuffle_results[sel_session][aa]={}\n",
    "        for p in predict:\n",
    "            plot_results[sel_session][aa][p]={}\n",
    "            plot_shuffle_results[sel_session][aa][p]={}\n",
    "            for ll in label_list:\n",
    "                plot_results[sel_session][aa][p][ll]=np.zeros((len(timepoints),n_repeats))\n",
    "                plot_results[sel_session][aa][p][ll][:]=np.nan\n",
    "                \n",
    "                plot_shuffle_results[sel_session][aa][p][ll]=np.zeros((len(timepoints),n_repeats))\n",
    "                plot_shuffle_results[sel_session][aa][p][ll][:]=np.nan\n",
    "\n",
    "    \n",
    "# diff table for each timepoint?\n",
    "# row = session\n",
    "# columns = ['modality','A_vis','A_aud','B_vis','B_aud','C_vis','C_aud','F_vis','F_aud',]\n",
    "\n",
    "decoder_acc_session_mean = {}\n",
    "decoder_acc_session_shuffle_mean = {}\n",
    "for aa in areas:\n",
    "    decoder_acc_session_mean[aa]={}\n",
    "    decoder_acc_session_shuffle_mean[aa]={}\n",
    "    for p in predict:\n",
    "        decoder_acc_session_mean[aa][p]={}\n",
    "        decoder_acc_session_shuffle_mean[aa][p]={}\n",
    "        for ll in label_list:\n",
    "            \n",
    "            decoder_acc_session_mean[aa][p][ll]=np.zeros((len(timepoints),\n",
    "                                                           len(main_path)))\n",
    "            decoder_acc_session_mean[aa][p][ll][:]=np.nan\n",
    "            \n",
    "            decoder_acc_session_shuffle_mean[aa][p][ll]=np.zeros((len(timepoints),\n",
    "                                                           len(main_path)))\n",
    "            decoder_acc_session_shuffle_mean[aa][p][ll][:]=np.nan\n",
    "        \n",
    "\n",
    "for sel_session in range(0,len(svc_results)):\n",
    "    for p in predict:\n",
    "        for aa in areas: \n",
    "            if aa in svc_results[sel_session][p].keys():\n",
    "                for tt,tp in enumerate(timepoints):\n",
    "                    for nn in range(0,n_repeats):\n",
    "                        for ll in label_list:\n",
    "                            if len(svc_results[sel_session][p][aa])>0:\n",
    "                                if len(svc_results[sel_session][p][aa][tt])>0:\n",
    "                                    if ll in svc_results[sel_session][p][aa][tt][nn]['cr'].keys():\n",
    "                                        temp_perf=np.nanmean(svc_results[sel_session][p]\n",
    "                                                          [aa][tt][nn]['cr'][ll]\n",
    "                                                          [['precision','recall']].values)\n",
    "                                        plot_results[sel_session][aa][p][ll][tt,nn]=temp_perf\n",
    "                                        \n",
    "                                        temp_shuff_perf=np.nanmean(svc_results[sel_session][p]\n",
    "                                                          [aa][tt][nn]['shuffle']['cr'][ll]\n",
    "                                                          [['precision','recall']].values)\n",
    "                                        plot_shuffle_results[sel_session][aa][p][ll][tt,nn]=temp_shuff_perf\n",
    "\n",
    "                    for ll in label_list:\n",
    "                        if len(svc_results[sel_session][p][aa])>0:                    \n",
    "                            decoder_acc_mean = np.nanmean(plot_results[sel_session][aa][p][ll][tt])\n",
    "                            decoder_acc_session_mean[aa][p][ll][tt,sel_session] = decoder_acc_mean\n",
    "    \n",
    "                            decoder_acc_shuffle_mean = np.nanmean(plot_shuffle_results[sel_session][aa][p][ll][tt])\n",
    "                            decoder_acc_session_shuffle_mean[aa][p][ll][tt,sel_session] = decoder_acc_shuffle_mean\n",
    "# plot_results[area][label/stimulus][timepoint_idx][ntrials_idx,nunits_idx,n_repeats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec26037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_results[sel_session][p][aa][tt][nn]['balance_running']['cr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdea79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_results[0]['block_ids']['MOs'][0][0]#['cr']['vis1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00dfc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_var='block_ids'\n",
    "sel_stim='vis1'\n",
    "\n",
    "fig,ax=plt.subplots(1,1)\n",
    "\n",
    "ax.axvline(0,color='k',linestyle='--',linewidth=1)\n",
    "ax.axhline(0.25,color='k',linestyle='--',linewidth=1)\n",
    "\n",
    "ax.plot(time_bins[1:],decoder_acc_session_mean['VISp'][predict_var][sel_stim],'k',linewidth=0.75,alpha=0.5)\n",
    "# ax.plot(time_bins[1:],decoder_acc_session_mean['AUDp'][predict_var][sel_stim],'m',linewidth=0.75,alpha=0.5)\n",
    "ax.plot(time_bins[1:],decoder_acc_session_mean['MOs'][predict_var][sel_stim],'b',linewidth=0.75,alpha=0.5)\n",
    "# ax.plot(time_bins[1:],decoder_acc_session_mean['MRN'][predict_var][sel_stim],'r',linewidth=0.75,alpha=0.5)\n",
    "# ax.plot(time_bins[1:],decoder_acc_session_mean['CP'][predict_var][sel_stim],'g',linewidth=0.75,alpha=0.5)\n",
    "\n",
    "\n",
    "visp_line=ax.plot(time_bins[1:],np.nanmean(decoder_acc_session_mean['VISp'][predict_var][sel_stim],axis=1)\n",
    "        ,'k.-',linewidth=2)\n",
    "\n",
    "visp_line_balance_running=ax.plot(time_bins[1:],\n",
    "                                  np.nanmean(decoder_acc_session_shuffle_mean['VISp'][predict_var][sel_stim],axis=1)\n",
    "                                  ,'k^--',linewidth=1.5)\n",
    "\n",
    "# ax.plot(time_bins[1:],np.nanmean(decoder_acc_session_mean['AUDp'][predict_var][sel_stim],axis=1)\n",
    "#         ,'m.-',linewidth=2)\n",
    "mos_line=ax.plot(time_bins[1:],np.nanmean(decoder_acc_session_mean['MOs'][predict_var][sel_stim],axis=1)\n",
    "        ,'b.-',linewidth=2)\n",
    "\n",
    "mos_line_balance_running=ax.plot(time_bins[1:],\n",
    "                                  np.nanmean(decoder_acc_session_shuffle_mean['MOs'][predict_var][sel_stim],axis=1)\n",
    "                                  ,'b^--',linewidth=1.5)\n",
    "\n",
    "# ax.plot(time_bins[1:],np.nanmean(decoder_acc_session_mean['MRN'][predict_var][sel_stim],axis=1)\n",
    "#         ,'r.-',linewidth=2)\n",
    "# ax.plot(time_bins[1:],np.nanmean(decoder_acc_session_mean['CP'][predict_var][sel_stim],axis=1)\n",
    "#         ,'g.-',linewidth=2)\n",
    "\n",
    "\n",
    "ax.set_ylim([0.4,1.0])\n",
    "ax.set_xlabel('time relative to stim onset (s)')\n",
    "ax.set_ylabel('block decoding accuracy')\n",
    "ax.set_title('decode: '+sel_stim)\n",
    "# ax.legend([visp_line[0],mos_line[0]],['VISp','MOs'])\n",
    "# ax.legend([visp_line[0],visp_line_balance_running[0],mos_line[0],mos_line_balance_running[0]],\n",
    "#           ['VISp','VISp-balanced running','MOs','MOs-balanced running'])\n",
    "ax.legend([visp_line[0],visp_line_balance_running[0],mos_line[0],mos_line_balance_running[0]],\n",
    "          ['VISp','VISp-shuffle','MOs','MOs-shuffle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e434c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_var='block_ids'\n",
    "sel_stim='vis1'\n",
    "\n",
    "fig,ax=plt.subplots(1,1)\n",
    "\n",
    "ax.axvline(0,color='k',linestyle='--',linewidth=1)\n",
    "ax.axhline(0.5,color='k',linestyle='--',linewidth=1)\n",
    "\n",
    "\n",
    "visp_line=ax.errorbar(time_bins[1:],np.nanmean(decoder_acc_session_mean['VISp'][predict_var][sel_stim],axis=1),\n",
    "                      yerr=np.nanstd(decoder_acc_session_mean['VISp'][predict_var][sel_stim],axis=1)/\n",
    "                      np.sqrt(decoder_acc_session_mean['VISp'][predict_var][sel_stim].shape[1]),\n",
    "                      fmt='k.-',linewidth=2, capsize=2)\n",
    "\n",
    "\n",
    "visp_line_balance_running=ax.errorbar(time_bins[1:],\n",
    "                                    np.nanmean(decoder_acc_session_shuffle_mean['VISp'][predict_var][sel_stim],axis=1),\n",
    "                                    yerr=np.nanstd(decoder_acc_session_shuffle_mean['VISp'][predict_var][sel_stim],axis=1)/\n",
    "                                    np.sqrt(decoder_acc_session_shuffle_mean['VISp'][predict_var][sel_stim].shape[1]),\n",
    "                                    fmt='k^--',linewidth=1.5, capsize=2)\n",
    "\n",
    "\n",
    "mos_line=ax.errorbar(time_bins[1:],np.nanmean(decoder_acc_session_mean['MOs'][predict_var][sel_stim],axis=1),\n",
    "                     yerr=np.nanstd(decoder_acc_session_mean['MOs'][predict_var][sel_stim],axis=1)/\n",
    "                     np.sqrt(decoder_acc_session_mean['MOs'][predict_var][sel_stim].shape[1]),\n",
    "                     fmt='b.-',linewidth=2, capsize=2)\n",
    "\n",
    "\n",
    "mos_line_balance_running=ax.errorbar(time_bins[1:],\n",
    "                                    np.nanmean(decoder_acc_session_shuffle_mean['MOs'][predict_var][sel_stim],axis=1),\n",
    "                                    yerr=np.nanstd(decoder_acc_session_shuffle_mean['MOs'][predict_var][sel_stim],axis=1)/\n",
    "                                    np.sqrt(decoder_acc_session_shuffle_mean['MOs'][predict_var][sel_stim].shape[1]),\n",
    "                                    fmt='b^--',linewidth=1.5, capsize=2)\n",
    "\n",
    "\n",
    "\n",
    "ax.set_ylim([0.4,1.0])\n",
    "ax.set_xlabel('time relative to stim onset (s)')\n",
    "ax.set_ylabel('block decoding accuracy')\n",
    "ax.set_title('decode: '+sel_stim)\n",
    "# ax.legend([visp_line[0],mos_line[0]],['VISp','MOs'])\n",
    "# ax.legend([visp_line[0],visp_line_balance_running[0],mos_line[0],mos_line_balance_running[0]],\n",
    "#           ['VISp','VISp-balanced running','MOs','MOs-balanced running'])\n",
    "ax.legend([visp_line[0],visp_line_balance_running[0],mos_line[0],mos_line_balance_running[0]],\n",
    "          ['VISp','VISp-shuffle','MOs','MOs-shuffle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54e9565",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecd3570",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shaded error bars - MOs only\n",
    "\n",
    "predict_var='block_ids'\n",
    "sel_stim='vis1'\n",
    "\n",
    "sel_area='VPM'\n",
    "\n",
    "fig,ax=plt.subplots(1,1)\n",
    "\n",
    "ax.axvline(0,color='k',linestyle='--',linewidth=1)\n",
    "# ax.axhline(0.25,color='k',linestyle='--',linewidth=1)\n",
    "\n",
    "\n",
    "y1=np.nanmean(decoder_acc_session_mean[sel_area][predict_var][sel_stim],axis=1)\n",
    "err1=(np.nanstd(decoder_acc_session_mean[sel_area][predict_var][sel_stim],axis=1)/\n",
    "      np.sqrt(np.sum(~np.isnan(decoder_acc_session_mean[sel_area][predict_var][sel_stim][0,:]))))\n",
    "l1=ax.plot(time_bins[1:], y1,'k',linestyle='-')\n",
    "plt.fill_between(time_bins[1:], y1-err1, y1+err1,\n",
    "    alpha=0.2, edgecolor=None, facecolor='k')\n",
    "\n",
    "\n",
    "y2=np.nanmean(decoder_acc_session_shuffle_mean[sel_area][predict_var][sel_stim],axis=1)\n",
    "err2=(np.nanstd(decoder_acc_session_shuffle_mean[sel_area][predict_var][sel_stim],axis=1)/\n",
    "      np.sqrt(np.sum(~np.isnan(decoder_acc_session_shuffle_mean[sel_area][predict_var][sel_stim][0,:]))))\n",
    "l2=ax.plot(time_bins[1:], y2,'k',linestyle='--')\n",
    "plt.fill_between(time_bins[1:], y2-err1, y2+err1,\n",
    "    alpha=0.2, edgecolor=None, facecolor='k')\n",
    "\n",
    "\n",
    "\n",
    "ax.set_ylim([0.44,1.0])\n",
    "# ax.set_ylim([0.15,1.0])\n",
    "ax.set_xlabel('time relative to stim onset (s)')\n",
    "ax.set_ylabel('stimulus decoding accuracy')\n",
    "ax.set_title('decode: '+sel_stim)\n",
    "# ax.legend([visp_line[0],mos_line[0]],['VISp','MOs'])\n",
    "# ax.legend([visp_line[0],visp_line_balance_running[0],mos_line[0],mos_line_balance_running[0]],\n",
    "#           ['VISp','VISp-balanced running','MOs','MOs-balanced running'])\n",
    "ax.legend([l1[0],l2[0]],[sel_area,sel_area+'-shuffle'])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca0ac2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiple areas - sharded error bars\n",
    "\n",
    "#shaded error bars - MOs only\n",
    "\n",
    "predict_var='block_ids'\n",
    "sel_stim='vis1'\n",
    "\n",
    "fig,ax=plt.subplots(1,1)\n",
    "\n",
    "ax.axvline(0,color='k',linestyle='--',linewidth=1)\n",
    "# ax.axhline(0.25,color='k',linestyle='--',linewidth=1)\n",
    "\n",
    "\n",
    "y1=np.nanmean(decoder_acc_session_mean['MOs'][predict_var][sel_stim],axis=1)\n",
    "err1=(np.nanstd(decoder_acc_session_mean['MOs'][predict_var][sel_stim],axis=1)/\n",
    "      np.sqrt(np.sum(~np.isnan(decoder_acc_session_mean['MOs'][predict_var][sel_stim][0,:]))))\n",
    "l1=ax.plot(time_bins[1:], y1,'k',linestyle='-')\n",
    "plt.fill_between(time_bins[1:], y1-err1, y1+err1,\n",
    "    alpha=0.2, edgecolor=None, facecolor='k')\n",
    "\n",
    "\n",
    "y2=np.nanmean(decoder_acc_session_shuffle_mean['MOs'][predict_var][sel_stim],axis=1)\n",
    "err2=(np.nanstd(decoder_acc_session_shuffle_mean['MOs'][predict_var][sel_stim],axis=1)/\n",
    "      np.sqrt(np.sum(~np.isnan(decoder_acc_session_shuffle_mean['MOs'][predict_var][sel_stim][0,:]))))\n",
    "l2=ax.plot(time_bins[1:], y2,'k',linestyle='--')\n",
    "plt.fill_between(time_bins[1:], y2-err1, y2+err1,\n",
    "    alpha=0.2, edgecolor=None, facecolor='k')\n",
    "\n",
    "\n",
    "ax.set_ylim([0.44,1.0])\n",
    "# ax.set_ylim([0.15,1.0])\n",
    "ax.set_xlabel('time relative to stim onset (s)')\n",
    "ax.set_ylabel('stimulus decoding accuracy')\n",
    "ax.set_title('decode: '+sel_stim)\n",
    "# ax.legend([visp_line[0],mos_line[0]],['VISp','MOs'])\n",
    "# ax.legend([visp_line[0],visp_line_balance_running[0],mos_line[0],mos_line_balance_running[0]],\n",
    "#           ['VISp','VISp-balanced running','MOs','MOs-balanced running'])\n",
    "ax.legend([l1[0],l2[0]],['MOs','MOs-shuffle'])\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f63e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cac28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir(loadpath)\n",
    "# decoder_acc_session_mean['VISp'][predict_var][sel_stim].shape[1]\n",
    "np.sum(~np.isnan(decoder_acc_session_mean['MOs'][predict_var][sel_stim][0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2844d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(loadpath,decoder_results[0]),'rb') as handle:\n",
    "#     X=pickle.load(handle)        \n",
    "# X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a0967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X['metadata']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:allensdk_38_new]",
   "language": "python",
   "name": "conda-env-allensdk_38_new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
