{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "743f5c21",
   "metadata": {},
   "source": [
    "# Decode stimuli/block/licks from neural activity - DR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d7bb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.signal as sg\n",
    "import scipy.stats as st\n",
    "import xarray as xr\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import ast\n",
    "from sklearn import svm\n",
    "import glob\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from DR_analysis_utils import Session, makePSTH, make_neuron_time_trials_tensor, compute_smoothed_response_rate\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95638ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set paths to experiment folders\n",
    "main_path = [\n",
    "    r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\PilotEphys\\Task 2 pilot\\DRpilot_626791_20220815\\processed\",\n",
    "    r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\PilotEphys\\Task 2 pilot\\DRpilot_626791_20220816\\processed\",\n",
    "    r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\PilotEphys\\Task 2 pilot\\DRpilot_626791_20220817\\processed\",\n",
    "    r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\PilotEphys\\Task 2 pilot\\DRpilot_636766_20230123\\processed\", \n",
    "    r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\PilotEphys\\Task 2 pilot\\DRpilot_636766_20230124\\processed\", \n",
    "    r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\PilotEphys\\Task 2 pilot\\DRpilot_636766_20230125\\processed\", \n",
    "    r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\PilotEphys\\Task 2 pilot\\DRpilot_636766_20230126\\processed\", \n",
    "    r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\PilotEphys\\Task 2 pilot\\DRpilot_644864_20230130\\processed\",\n",
    "    r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\PilotEphys\\Task 2 pilot\\DRpilot_644864_20230131\\processed\", \n",
    "    r\"\\\\allen\\programs\\mindscope\\workgroups\\dynamicrouting\\PilotEphys\\Task 2 pilot\\DRpilot_644864_20230201\\processed\", \n",
    "    r\"\\\\allen\\programs\\mindscope\\workgroups\\np-exp\\PilotEphys\\Task 2 pilot\\DRpilot_644864_20230202\\processed\",\n",
    "#     r\"\\\\allen\\programs\\mindscope\\workgroups\\np-exp\\PilotEphys\\Task 2 pilot\\DRpilot_644866_20230207\\processed\", \n",
    "#     r\"Y:\\DRpilot_644866_20230208\\processed\",\n",
    "#     r\"Y:\\DRpilot_644866_20230209\\processed\",\n",
    "#     r\"Y:\\DRpilot_644866_20230210\\processed\",\n",
    "    r\"Y:\\DRpilot_644867_20230220\\processed\",\n",
    "    r\"Y:\\DRpilot_644867_20230221\\processed\",\n",
    "    r\"Y:\\DRpilot_644867_20230222\\processed\",\n",
    "    r\"Y:\\DRpilot_644867_20230223\\processed\",\n",
    "    r\"Y:\\DRpilot_649943_20230213\\processed\", \n",
    "    r\"Y:\\DRpilot_649943_20230214\\processed\",\n",
    "    r\"Y:\\DRpilot_649943_20230215\\processed\",\n",
    "    r\"Y:\\DRpilot_649943_20230216\\processed\",\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4797aa",
   "metadata": {},
   "source": [
    "## Load a single session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c89769",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sel_session=0\n",
    "session=Session(path=main_path[sel_session]) \n",
    "session.assign_unit_areas()\n",
    "session=compute_smoothed_response_rate(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd521600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trials table\n",
    "session.trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05999c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# units table\n",
    "session.good_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57fe109",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.good_units['area'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1467c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spike times from one unit\n",
    "session.spike_times[session.units.index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c008d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# information about each frame\n",
    "session.frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45556453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through sessions and make unit xarrays\n",
    "time_before_flash = 0.5\n",
    "trial_duration = 1.5\n",
    "bin_size = 0.001\n",
    "\n",
    "\n",
    "# Make tensor (3-D matrix [units,time,trials])\n",
    "trial_tensor = make_neuron_time_trials_tensor(session.good_units, session.spike_times, \n",
    "                                              session.trials,time_before_flash, trial_duration, \n",
    "                                              bin_size)\n",
    "\n",
    "# make xarray\n",
    "session.trial_da = xr.DataArray(trial_tensor, dims=(\"unit_id\", \"time\", \"trials\"), \n",
    "                           coords={\n",
    "                               \"unit_id\": session.good_units.index.values,\n",
    "                               \"time\": np.arange(0, trial_duration, bin_size)-time_before_flash,\n",
    "                               \"trials\": session.trials.index.values\n",
    "                               })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df77a7fc",
   "metadata": {},
   "source": [
    "### decode by area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1bb092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# session.good_units['area'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250d71f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shorten the area names to better lump together units\n",
    "#get rig of layers and/or sub-areas with dashes\n",
    "area_short = []\n",
    "for area in session.good_units['area']:\n",
    "    if area=='N/A':\n",
    "        short='N/A'\n",
    "    elif area[:2]=='CA':\n",
    "        short=area\n",
    "    else:\n",
    "        dig_ind=re.search(r\"\\d\", area)\n",
    "        dash_ind=re.search(r\"-\", area)\n",
    "        if dig_ind!=None:\n",
    "            short=area[:dig_ind.start()]\n",
    "        elif dash_ind!=None:\n",
    "            short=area[:dash_ind.start()]\n",
    "        else:\n",
    "            short=area\n",
    "        \n",
    "    area_short.append(short)\n",
    "    \n",
    "session.good_units['area_short']=area_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c656ac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_counts=session.good_units['area_short'].value_counts()\n",
    "area_counts[area_counts>35].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2e01e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f92d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # grab data: make these [trials,neurons] matrices based on different time bins:\n",
    "# trial_sel=session.trials.query('(trialStimID == \"sound1\" and trial_response == True)').index\n",
    "\n",
    "# area_sel = area_counts[area_counts>25].index\n",
    "\n",
    "# # grab the stimulus ids\n",
    "# stim_ids = session.trials['trialStimID'][trial_sel].values\n",
    "# # or, use block IDs\n",
    "# block_ids = session.trials['trialstimRewarded'][trial_sel].values\n",
    "# #or, use whether mouse responded\n",
    "# trial_response = session.trials['trial_response'][trial_sel].values\n",
    "\n",
    "# # choose what variable to predict\n",
    "# pred_var = block_ids\n",
    "\n",
    "# ### make sure equal # of trials per condition!\n",
    "# conds = np.unique(pred_var)\n",
    "# cond_count = np.zeros(len(conds))\n",
    "# for ic,cc in enumerate(conds):\n",
    "#     cond_count[ic]=np.sum(pred_var==cc)\n",
    "    \n",
    "# min_n_trials=np.min(cond_count).astype(int)\n",
    "\n",
    "# subset_ind=[]\n",
    "\n",
    "# for cc in conds:\n",
    "#     cond_inds=np.where(pred_var==cc)[0]\n",
    "#     subset_ind.append(np.random.choice(cond_inds,min_n_trials,replace=False))\n",
    "    \n",
    "# subset_ind=np.sort(np.hstack(subset_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef49be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c36fa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try more timepoints & split by areas\n",
    "\n",
    "svc_results={}\n",
    "binsize=0.1\n",
    "\n",
    "# grab data: make these [trials,neurons] matrices based on different time bins:\n",
    "\n",
    "hit_trials = session.trials.query(\n",
    "    '(trialStimID == \"vis1\" and \\\n",
    "    trialstimRewarded == \"vis1\" and \\\n",
    "    trial_response == True and \\\n",
    "    vis_autoreward_trials == False) or \\\n",
    "    (trialStimID == \"sound1\" and \\\n",
    "    trialstimRewarded == \"sound1\" and \\\n",
    "    trial_response == True and \\\n",
    "    vis_autoreward_trials == False)').index\n",
    "\n",
    "cr_trials = session.trials.query(\n",
    "    '(trialStimID == \"vis1\" and \\\n",
    "    trialstimRewarded == \"sound1\" and \\\n",
    "    trial_response == False and \\\n",
    "    vis_autoreward_trials == False) or \\\n",
    "    (trialStimID == \"sound1\" and \\\n",
    "    trialstimRewarded == \"vis1\" and \\\n",
    "    trial_response == False and \\\n",
    "    vis_autoreward_trials == False)').index\n",
    "\n",
    "\n",
    "trial_sel=np.sort(np.hstack([hit_trials,cr_trials]))\n",
    "\n",
    "area_sel = area_counts[area_counts>30].index\n",
    "# area_sel = ['all']\n",
    "\n",
    "# grab the stimulus ids\n",
    "stim_ids = session.trials['trialStimID'][trial_sel].values\n",
    "# or, use block IDs\n",
    "block_ids = session.trials['trialstimRewarded'][trial_sel].values\n",
    "#or, use whether mouse responded\n",
    "trial_response = session.trials['trial_response'][trial_sel].values\n",
    "\n",
    "#choose what variable to predict\n",
    "pred_var = block_ids\n",
    "\n",
    "### make sure equal # of trials per condition!\n",
    "conds = np.unique(pred_var)\n",
    "cond_count = np.zeros(len(conds))\n",
    "for ic,cc in enumerate(conds):\n",
    "    cond_count[ic]=np.sum(pred_var==cc)\n",
    "min_n_trials=np.min(cond_count).astype(int)\n",
    "subset_ind=[]\n",
    "for cc in conds:\n",
    "    cond_inds=np.where(pred_var==cc)[0]\n",
    "    subset_ind.append(np.random.choice(cond_inds,min_n_trials,replace=False))   \n",
    "subset_ind=np.sort(np.hstack(subset_ind))\n",
    "trial_sel=trial_sel[subset_ind]\n",
    "pred_var=pred_var[subset_ind]\n",
    "\n",
    "trnum=40\n",
    "u_num=30\n",
    "\n",
    "n_repeats=100\n",
    "\n",
    "time_bins=np.arange(-0.2,0.6,binsize)\n",
    "\n",
    "for aa in area_sel:\n",
    "    if aa=='all':\n",
    "        unit_sel = session.good_units.index.values\n",
    "    else:\n",
    "        unit_sel = session.good_units.query('area_short==@aa').index.values\n",
    "    svc_results[aa]={}\n",
    "    \n",
    "    for tt,t_start in enumerate(time_bins[:-1]):\n",
    "        svc_results[aa][tt]={}\n",
    "        \n",
    "        for nn in range(0,n_repeats):\n",
    "            unit_subset = np.random.choice(unit_sel,u_num,replace=True)\n",
    "\n",
    "            ### make sure equal # of trials per condition!\n",
    "            subset_ind=[]\n",
    "            conds = np.unique(pred_var)\n",
    "            cond_count=[]\n",
    "\n",
    "            for cc in conds:\n",
    "                cond_inds=np.where(pred_var==cc)[0]\n",
    "                subset_ind.append(np.random.choice(cond_inds,trnum,replace=False))   \n",
    "            subset_ind=np.sort(np.hstack(subset_ind))\n",
    "\n",
    "            sel_data = session.trial_da.sel(time=slice(t_start,time_bins[tt+1]),\n",
    "                                            trials=trial_sel[subset_ind],\n",
    "                                            unit_id=unit_subset).mean(dim='time').values\n",
    "\n",
    "    #         sel_data = session.trial_da.sel(time=slice(t_start,time_bins[tt+1]),\n",
    "    #                                         trials=trial_sel,unit_id=unit_sel).mean(dim='time').values\n",
    "\n",
    "            X = sel_data.T\n",
    "            y = pred_var[subset_ind].flatten()\n",
    "\n",
    "            xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.5, stratify=y)\n",
    "\n",
    "            clf = svm.LinearSVC()\n",
    "            clf.fit(xtrain, ytrain)\n",
    "\n",
    "            ypred = clf.predict(xtest)\n",
    "\n",
    "            cr_dict=classification_report(ytest, ypred, output_dict=True)\n",
    "            cr_df=pd.DataFrame.from_dict(cr_dict)\n",
    "\n",
    "            svc_results[aa][tt][nn]=cr_df\n",
    "    \n",
    "    print(aa+' done')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa02982",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_trials.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2187881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make into more plottable format\n",
    "\n",
    "plot_results={}\n",
    "\n",
    "timepoints=time_bins[1:]\n",
    "\n",
    "areas=area_sel\n",
    "\n",
    "for aa in areas:\n",
    "    plot_results[aa]={}\n",
    "#     plot_results[tt]['modality']=modality\n",
    "    plot_results[aa]['vis1']=np.zeros((len(timepoints),n_repeats))\n",
    "    plot_results[aa]['vis1'][:]=np.nan\n",
    "    plot_results[aa]['vis2']=np.zeros((len(timepoints),n_repeats))\n",
    "    plot_results[aa]['vis2'][:]=np.nan\n",
    "    plot_results[aa]['aud1']=np.zeros((len(timepoints),n_repeats))\n",
    "    plot_results[aa]['aud1'][:]=np.nan\n",
    "    plot_results[aa]['aud2']=np.zeros((len(timepoints),n_repeats))\n",
    "    plot_results[aa]['aud2'][:]=np.nan\n",
    "    \n",
    "    plot_results[aa]['True']=np.zeros((len(timepoints),n_repeats))\n",
    "    plot_results[aa]['True'][:]=np.nan\n",
    "    plot_results[aa]['False']=np.zeros((len(timepoints),n_repeats))\n",
    "    plot_results[aa]['False'][:]=np.nan\n",
    "#     for tt,tp in enumerate(timepoints):\n",
    "#         plot_results[aa][tt]=[]\n",
    "        \n",
    "\n",
    "         \n",
    "# diff table for each timepoint?\n",
    "# row = session\n",
    "# columns = ['modality','A_vis','A_aud','B_vis','B_aud','C_vis','C_aud','F_vis','F_aud',]\n",
    "\n",
    "for aa in areas: #svc_results[ss]['results'].keys():\n",
    "    if aa in svc_results.keys():\n",
    "        for tt,tp in enumerate(timepoints):\n",
    "            \n",
    "            for nn in range(0,n_repeats):\n",
    "                if 'vis1' in svc_results[aa][tt][nn].keys():\n",
    "                    vis1_perf=np.mean(svc_results[aa][tt][nn]['vis1'][['precision','recall']].values)\n",
    "                    plot_results[aa]['vis1'][tt,nn]=vis1_perf\n",
    "\n",
    "                if 'vis2' in svc_results[aa][tt][nn].keys():\n",
    "                    vis2_perf=np.mean(svc_results[aa][tt][nn]['vis2'][['precision','recall']].values)\n",
    "                    plot_results[aa]['vis2'][tt,nn]=vis2_perf\n",
    "\n",
    "                if 'sound1' in svc_results[aa][tt][nn].keys():\n",
    "                    aud1_perf=np.mean(svc_results[aa][tt][nn]['sound1'][['precision','recall']].values)\n",
    "                    plot_results[aa]['aud1'][tt,nn]=aud1_perf\n",
    "\n",
    "                if 'sound2' in svc_results[aa][tt][nn].keys():\n",
    "                    aud2_perf=np.mean(svc_results[aa][tt][nn]['sound2'][['precision','recall']].values)\n",
    "                    plot_results[aa]['aud2'][tt,nn]=aud2_perf\n",
    "\n",
    "                if 'True' in svc_results[aa][tt][nn].keys():\n",
    "                    aud1_perf=np.mean(svc_results[aa][tt][nn]['True'][['precision','recall']].values)\n",
    "                    plot_results[aa]['True'][tt,nn]=aud1_perf\n",
    "\n",
    "                if 'False' in svc_results[aa][tt][nn].keys():\n",
    "                    aud2_perf=np.mean(svc_results[aa][tt][nn]['False'][['precision','recall']].values)\n",
    "                    plot_results[aa]['False'][tt,nn]=aud2_perf\n",
    "\n",
    "#     plot_results[tt]=pd.DataFrame.from_dict(plot_results[tt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4a9e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_results[aa][tt][nn]['vis1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b15de1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot_results\n",
    "np.std(np.hstack([plot_results[area]['vis1'],plot_results[area]['aud1']]),1)\n",
    "# np.hstack([plot_results[area]['vis1'],plot_results[area]['aud1']]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98ef65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,1,figsize=(6,4))\n",
    "\n",
    "\n",
    "\n",
    "for aa,area in enumerate(plot_results.keys()):\n",
    "    y=np.nanmean([np.mean(plot_results[area]['vis1'],1),np.mean(plot_results[area]['aud1'],1)],0)\n",
    "    yerr=np.std(np.hstack([plot_results[area]['vis1'],plot_results[area]['aud1']]),1)/np.sqrt(n_repeats)\n",
    "#     ax.plot(timepoints,np.mean([plot_results[area]['vis1'],plot_results[area]['aud1']],0))\n",
    "    linex=ax.plot(timepoints,y)\n",
    "    plt.fill_between(timepoints, y-yerr, y+yerr,\n",
    "                    alpha=0.2, edgecolor=None, facecolor=linex[0].get_color())\n",
    "    \n",
    "#     ax[aa].plot(timepoints,plot_results[area]['aud1'])\n",
    "\n",
    "ax.set_ylim([0.4,1.0])\n",
    "ax.axvline(0,color='k')\n",
    "# ax.axhline(0.25,color='k',linewidth=0.5,linestyle='--')\n",
    "ax.axhline(0.5,color='k',linewidth=0.5,linestyle='--')\n",
    "ax.set_title(session.metadata['mouseID']+' session '+str(session.metadata['ephys_session_num'])+\n",
    "            '; n_units='+str(u_num)+'; n_trials='+str(trnum)+'; n_repeats='+str(n_repeats))\n",
    "# ax.set_title(area)\n",
    "# ax.set_xticklabels('')\n",
    "ax.legend(plot_results.keys(),ncol=3)\n",
    "ax.set_ylabel('decodability of context')\n",
    "ax.set_xlabel('time from stimulus onset (s)')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7d80d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax=plt.subplots(len(plot_results.keys()),1,figsize=(6,20))\n",
    "\n",
    "# if type(ax)!=np.ndarray:\n",
    "#     ax=[ax]\n",
    "\n",
    "# for aa,area in enumerate(plot_results.keys()):\n",
    "#     ax[aa].plot(timepoints,np.mean([plot_results[area]['vis1'],plot_results[area]['aud1']],0))\n",
    "# #     ax[aa].plot(timepoints,plot_results[area]['aud1'])\n",
    "#     ax[aa].set_ylim([-0.1,1.1])\n",
    "#     ax[aa].axvline(0,color='k')\n",
    "#     ax[aa].axhline(0.25,color='k',linewidth=0.5,linestyle='--')\n",
    "#     ax[aa].axhline(0.5,color='k',linewidth=0.5,linestyle='--')\n",
    "#     ax[aa].set_title(area)\n",
    "#     if aa<len(plot_results.keys())-1:\n",
    "#         ax[aa].set_xticklabels('')\n",
    "\n",
    "# ax[aa].set_xlabel('time from stimulus onset (s)')\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98dad34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0954960",
   "metadata": {},
   "source": [
    "## loop through experiments & plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f839f6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trnum=30\n",
    "u_num=20\n",
    "n_repeats=100\n",
    "binsize=0.1\n",
    "time_bins=np.arange(-0.2,0.6,binsize)\n",
    "\n",
    "for sel_session, path in enumerate(main_path):\n",
    "    \n",
    "    session=[]\n",
    "    session=Session(path=path) \n",
    "    session.assign_unit_areas()\n",
    "    session=compute_smoothed_response_rate(session)\n",
    "    \n",
    "    # loop through sessions and make unit xarrays\n",
    "    time_before_flash = 0.25\n",
    "    trial_duration = 1.0\n",
    "    bin_size = 0.001\n",
    "\n",
    "    # Make tensor (3-D matrix [units,time,trials])\n",
    "    trial_tensor = make_neuron_time_trials_tensor(session.good_units, session.spike_times, \n",
    "                                                  session.trials,time_before_flash, trial_duration, \n",
    "                                                  bin_size)\n",
    "    # make xarray\n",
    "    session.trial_da = xr.DataArray(trial_tensor, dims=(\"unit_id\", \"time\", \"trials\"), \n",
    "                               coords={\n",
    "                                   \"unit_id\": session.good_units.index.values,\n",
    "                                   \"time\": np.arange(0, trial_duration, bin_size)-time_before_flash,\n",
    "                                   \"trials\": session.trials.index.values\n",
    "                                   })\n",
    "    \n",
    "    #shorten the area names to better lump together units\n",
    "    #get rig of layers and/or sub-areas with dashes\n",
    "    area_short = []\n",
    "    for area in session.good_units['area']:\n",
    "        if area=='N/A':\n",
    "            short='N/A'\n",
    "        elif area[:2]=='CA':\n",
    "            short=area\n",
    "        else:\n",
    "            dig_ind=re.search(r\"\\d\", area)\n",
    "            dash_ind=re.search(r\"-\", area)\n",
    "            if dig_ind!=None:\n",
    "                short=area[:dig_ind.start()]\n",
    "            elif dash_ind!=None:\n",
    "                short=area[:dash_ind.start()]\n",
    "            else:\n",
    "                short=area\n",
    "        area_short.append(short)\n",
    "    session.good_units['area_short']=area_short\n",
    "    area_counts=session.good_units['area_short'].value_counts()\n",
    "    \n",
    "    #try more timepoints & split by areas\n",
    "    svc_results={}\n",
    "    svc_results_shuff={}\n",
    "\n",
    "    # grab data: make these [trials,neurons] matrices based on different time bins:\n",
    "\n",
    "#     hit_trials = session.trials.query(\n",
    "#         '(trialStimID == \"vis1\" and \\\n",
    "#         trialstimRewarded == \"vis1\" and \\\n",
    "#         trial_response == True and \\\n",
    "#         vis_autoreward_trials == False) or \\\n",
    "#         (trialStimID == \"sound1\" and \\\n",
    "#         trialstimRewarded == \"sound1\" and \\\n",
    "#         trial_response == True and \\\n",
    "#         vis_autoreward_trials == False)').index\n",
    "\n",
    "#     cr_trials = session.trials.query(\n",
    "#         '(trialStimID == \"vis1\" and \\\n",
    "#         trialstimRewarded == \"sound1\" and \\\n",
    "#         trial_response == False and \\\n",
    "#         vis_autoreward_trials == False) or \\\n",
    "#         (trialStimID == \"sound1\" and \\\n",
    "#         trialstimRewarded == \"vis1\" and \\\n",
    "#         trial_response == False and \\\n",
    "#         vis_autoreward_trials == False)').index\n",
    "\n",
    "\n",
    "#     trial_sel=np.sort(np.hstack([hit_trials,cr_trials]))\n",
    "    \n",
    "    if 'trialOptoVoltage' in session.trials.columns:\n",
    "        trial_sel = session.trials.query('vis_autoreward_trials == False and \\\n",
    "                                          aud_autoreward_trials == False and \\\n",
    "                                          cross_modal_dprime >= 1.5 and \\\n",
    "                                          trialStimID != \"catch\" and \\\n",
    "                                          trialOptoVoltage.isnull()').index\n",
    "    else:\n",
    "        trial_sel = session.trials.query('vis_autoreward_trials == False and \\\n",
    "                                          aud_autoreward_trials == False and \\\n",
    "                                          cross_modal_dprime >= 1.5 and \\\n",
    "                                          trialStimID != \"catch\"').index\n",
    "    \n",
    "\n",
    "    # grab the stimulus ids\n",
    "    stim_ids = session.trials['trialStimID'][trial_sel].values\n",
    "    # or, use block IDs\n",
    "    block_ids = session.trials['trialstimRewarded'][trial_sel].values\n",
    "    #or, use whether mouse responded\n",
    "    trial_response = session.trials['trial_response'][trial_sel].values\n",
    "\n",
    "    #choose what variable to predict\n",
    "    pred_var = block_ids\n",
    "\n",
    "#     ### make sure equal # of trials per condition!\n",
    "#     conds = np.unique(pred_var)\n",
    "#     cond_count = np.zeros(len(conds))\n",
    "#     for ic,cc in enumerate(conds):\n",
    "#         cond_count[ic]=np.sum(pred_var==cc)\n",
    "#     min_n_trials=np.min(cond_count).astype(int)\n",
    "#     subset_ind=[]\n",
    "#     for cc in conds:\n",
    "#         cond_inds=np.where(pred_var==cc)[0]\n",
    "#         subset_ind.append(np.random.choice(cond_inds,min_n_trials,replace=False))   \n",
    "#     subset_ind=np.sort(np.hstack(subset_ind))\n",
    "#     trial_sel=trial_sel[subset_ind]\n",
    "#     pred_var=pred_var[subset_ind]\n",
    "\n",
    "\n",
    "    area_sel = area_counts[area_counts>=u_num].index\n",
    "    # area_sel = ['all']\n",
    "\n",
    "    for aa in area_sel:\n",
    "        if aa=='all':\n",
    "            unit_sel = session.good_units.index.values\n",
    "        else:\n",
    "            unit_sel = session.good_units.query('area_short==@aa').index.values\n",
    "        svc_results[aa]={}\n",
    "        svc_results_shuff[aa]={}\n",
    "\n",
    "        for tt,t_start in enumerate(time_bins[:-1]):\n",
    "            svc_results[aa][tt]={}\n",
    "            svc_results_shuff[aa][tt]={}\n",
    "\n",
    "            for nn in range(0,n_repeats):\n",
    "                unit_subset = np.random.choice(unit_sel,u_num,replace=True)\n",
    "\n",
    "                ### make sure equal # of trials per condition!\n",
    "                subset_ind=[]\n",
    "                conds = np.unique(pred_var)\n",
    "                cond_count=[]\n",
    "\n",
    "                for cc in conds:\n",
    "                    cond_inds=np.where(pred_var==cc)[0]\n",
    "                    if len(cond_inds)<trnum:\n",
    "                        trnum=len(cond_inds)\n",
    "                    subset_ind.append(np.random.choice(cond_inds,trnum,replace=False))   \n",
    "                subset_ind=np.sort(np.hstack(subset_ind))\n",
    "\n",
    "                sel_data = session.trial_da.sel(time=slice(t_start,time_bins[tt+1]),\n",
    "                                                trials=trial_sel[subset_ind],\n",
    "                                                unit_id=unit_subset).mean(dim='time').values\n",
    "                scaler = StandardScaler()\n",
    "                scaler.fit(sel_data.T)\n",
    "                X = scaler.transform(sel_data.T)\n",
    "#                 X = sel_data.T\n",
    "                y = pred_var[subset_ind].flatten()\n",
    "                \n",
    "                xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.5, stratify=y)\n",
    "\n",
    "                clf = svm.LinearSVC()\n",
    "                clf.fit(xtrain, ytrain)\n",
    "\n",
    "                ypred = clf.predict(xtest)\n",
    "\n",
    "                cr_dict=classification_report(ytest, ypred, output_dict=True)\n",
    "                cr_df=pd.DataFrame.from_dict(cr_dict)\n",
    "\n",
    "                svc_results[aa][tt][nn]=cr_df\n",
    "                \n",
    "                #shuffle labels & train\n",
    "                y_shuff = np.random.choice(y,len(y),replace=False)\n",
    "                \n",
    "                xtrain_shuff, xtest_shuff, ytrain_shuff, ytest_shuff = train_test_split(X, y_shuff, test_size=0.5, stratify=y)\n",
    "\n",
    "                clf = svm.LinearSVC()\n",
    "                clf.fit(xtrain_shuff, ytrain_shuff)\n",
    "\n",
    "                ypred_shuff = clf.predict(xtest_shuff)\n",
    "\n",
    "                cr_dict_shuff=classification_report(ytest_shuff, ypred_shuff, output_dict=True)\n",
    "                cr_df_shuff=pd.DataFrame.from_dict(cr_dict_shuff)\n",
    "\n",
    "                svc_results_shuff[aa][tt][nn]=cr_df_shuff\n",
    "                \n",
    "        print(aa+' done')\n",
    "        \n",
    "        \n",
    "    # make into more plottable format\n",
    "    plot_results={}\n",
    "    timepoints=time_bins[1:]\n",
    "    areas=area_sel\n",
    "\n",
    "    for aa in areas:\n",
    "        plot_results[aa]={}\n",
    "        plot_results[aa]['vis1']=np.zeros((len(timepoints),n_repeats))\n",
    "        plot_results[aa]['vis1'][:]=np.nan\n",
    "        plot_results[aa]['aud1']=np.zeros((len(timepoints),n_repeats))\n",
    "        plot_results[aa]['aud1'][:]=np.nan\n",
    "        \n",
    "        plot_results[aa]['True']=np.zeros((len(timepoints),n_repeats))\n",
    "        plot_results[aa]['True'][:]=np.nan\n",
    "        plot_results[aa]['False']=np.zeros((len(timepoints),n_repeats))\n",
    "        plot_results[aa]['False'][:]=np.nan\n",
    "\n",
    "    # diff table for each timepoint?\n",
    "    # row = session\n",
    "    # columns = ['modality','A_vis','A_aud','B_vis','B_aud','C_vis','C_aud','F_vis','F_aud',]\n",
    "\n",
    "    for aa in areas: #svc_results[ss]['results'].keys():\n",
    "        if aa in svc_results.keys():\n",
    "            for tt,tp in enumerate(timepoints):\n",
    "\n",
    "                for nn in range(0,n_repeats):\n",
    "                    if 'vis1' in svc_results[aa][tt][nn].keys():\n",
    "                        vis1_perf=np.mean(svc_results[aa][tt][nn]['vis1'][['precision','recall']].values)\n",
    "                        plot_results[aa]['vis1'][tt,nn]=vis1_perf\n",
    "\n",
    "                    if 'sound1' in svc_results[aa][tt][nn].keys():\n",
    "                        aud1_perf=np.mean(svc_results[aa][tt][nn]['sound1'][['precision','recall']].values)\n",
    "                        plot_results[aa]['aud1'][tt,nn]=aud1_perf\n",
    "                        \n",
    "                    if 'True' in svc_results[aa][tt][nn].keys():\n",
    "                        vis1_perf=np.mean(svc_results[aa][tt][nn]['True'][['precision','recall']].values)\n",
    "                        plot_results[aa]['True'][tt,nn]=vis1_perf\n",
    "\n",
    "                    if 'False' in svc_results[aa][tt][nn].keys():\n",
    "                        aud1_perf=np.mean(svc_results[aa][tt][nn]['False'][['precision','recall']].values)\n",
    "                        plot_results[aa]['False'][tt,nn]=aud1_perf\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig,ax=plt.subplots(1,1,figsize=(6,4))\n",
    "\n",
    "    for aa,area in enumerate(plot_results.keys()):\n",
    "        y=np.nanmean([np.mean(plot_results[area]['vis1'],1),np.mean(plot_results[area]['aud1'],1)],0)\n",
    "        yerr=np.std(np.hstack([plot_results[area]['vis1'],plot_results[area]['aud1']]),1)/np.sqrt(n_repeats)\n",
    "        \n",
    "#         y=np.nanmean([np.mean(plot_results[area]['True'],1),np.mean(plot_results[area]['False'],1)],0)\n",
    "#         yerr=np.std(np.hstack([plot_results[area]['True'],plot_results[area]['False']]),1)/np.sqrt(n_repeats)\n",
    "        \n",
    "        if aa>19:\n",
    "            linex=ax.plot(timepoints,y,linestyle='-.')\n",
    "        elif aa>9:\n",
    "            linex=ax.plot(timepoints,y,linestyle='--')\n",
    "        else:\n",
    "            linex=ax.plot(timepoints,y)\n",
    "        plt.fill_between(timepoints, y-yerr, y+yerr,\n",
    "                        alpha=0.2, edgecolor=None, facecolor=linex[0].get_color())\n",
    "\n",
    "    ax.set_ylim([0.4,1.0])\n",
    "    ax.axvline(0,color='k')\n",
    "    ax.axhline(0.5,color='k',linewidth=0.5,linestyle='--')\n",
    "    ax.set_title(session.metadata['mouseID']+' session '+str(session.metadata['ephys_session_num'])+\n",
    "                '; n_units='+str(u_num)+'; n_trials='+str(trnum)+'; n_repeats='+str(n_repeats))\n",
    "    ax.legend(plot_results.keys(),ncol=3)\n",
    "    ax.set_ylabel('decodability of context')\n",
    "    ax.set_xlabel('time from stimulus onset (s)')\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    figpath=r\"C:\\Users\\ethan.mcbride\\OneDrive - Allen Institute\\quick figures\\2023-04-04-DR_SAC_decoding_context\"\n",
    "\n",
    "    figname=(session.metadata['mouseID']+'_session_'+str(session.metadata['ephys_session_num'])+\n",
    "                '_n_units_'+str(u_num)+'_n_trials_'+str(trnum)+'_n_repeats_'+str(n_repeats)+'.png')\n",
    "    # figname='control_heatmap_500ms_all.png'\n",
    "    plt.savefig(os.path.join(figpath,figname), dpi=600, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "    \n",
    "    ### shuffled labels plot\n",
    "    # make into more plottable format\n",
    "    plot_results_shuff={}\n",
    "    timepoints=time_bins[1:]\n",
    "    areas=area_sel\n",
    "\n",
    "    for aa in areas:\n",
    "        plot_results_shuff[aa]={}\n",
    "        plot_results_shuff[aa]['vis1']=np.zeros((len(timepoints),n_repeats))\n",
    "        plot_results_shuff[aa]['vis1'][:]=np.nan\n",
    "        plot_results_shuff[aa]['aud1']=np.zeros((len(timepoints),n_repeats))\n",
    "        plot_results_shuff[aa]['aud1'][:]=np.nan\n",
    "        \n",
    "        plot_results_shuff[aa]['True']=np.zeros((len(timepoints),n_repeats))\n",
    "        plot_results_shuff[aa]['True'][:]=np.nan\n",
    "        plot_results_shuff[aa]['False']=np.zeros((len(timepoints),n_repeats))\n",
    "        plot_results_shuff[aa]['False'][:]=np.nan\n",
    "\n",
    "    # diff table for each timepoint?\n",
    "    # row = session\n",
    "    # columns = ['modality','A_vis','A_aud','B_vis','B_aud','C_vis','C_aud','F_vis','F_aud',]\n",
    "\n",
    "    for aa in areas: #svc_results[ss]['results'].keys():\n",
    "        if aa in svc_results_shuff.keys():\n",
    "            for tt,tp in enumerate(timepoints):\n",
    "\n",
    "                for nn in range(0,n_repeats):\n",
    "                    if 'vis1' in svc_results_shuff[aa][tt][nn].keys():\n",
    "                        vis1_perf=np.mean(svc_results_shuff[aa][tt][nn]['vis1'][['precision','recall']].values)\n",
    "                        plot_results_shuff[aa]['vis1'][tt,nn]=vis1_perf\n",
    "\n",
    "                    if 'sound1' in svc_results_shuff[aa][tt][nn].keys():\n",
    "                        aud1_perf=np.mean(svc_results_shuff[aa][tt][nn]['sound1'][['precision','recall']].values)\n",
    "                        plot_results_shuff[aa]['aud1'][tt,nn]=aud1_perf\n",
    "                        \n",
    "                    if 'True' in svc_results_shuff[aa][tt][nn].keys():\n",
    "                        vis1_perf=np.mean(svc_results_shuff[aa][tt][nn]['True'][['precision','recall']].values)\n",
    "                        plot_results_shuff[aa]['True'][tt,nn]=vis1_perf\n",
    "\n",
    "                    if 'False' in svc_results_shuff[aa][tt][nn].keys():\n",
    "                        aud1_perf=np.mean(svc_results_shuff[aa][tt][nn]['False'][['precision','recall']].values)\n",
    "                        plot_results_shuff[aa]['False'][tt,nn]=aud1_perf\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig,ax=plt.subplots(1,1,figsize=(6,4))\n",
    "\n",
    "    for aa,area in enumerate(plot_results.keys()):\n",
    "        y=np.nanmean([np.mean(plot_results_shuff[area]['vis1'],1),np.mean(plot_results_shuff[area]['aud1'],1)],0)\n",
    "        yerr=np.std(np.hstack([plot_results_shuff[area]['vis1'],plot_results_shuff[area]['aud1']]),1)/np.sqrt(n_repeats)\n",
    "        \n",
    "#         y=np.nanmean([np.mean(plot_results[area]['True'],1),np.mean(plot_results[area]['False'],1)],0)\n",
    "#         yerr=np.std(np.hstack([plot_results[area]['True'],plot_results[area]['False']]),1)/np.sqrt(n_repeats)\n",
    "        \n",
    "        if aa>19:\n",
    "            linex=ax.plot(timepoints,y,linestyle='-.')\n",
    "        elif aa>9:\n",
    "            linex=ax.plot(timepoints,y,linestyle='--')\n",
    "        else:\n",
    "            linex=ax.plot(timepoints,y)\n",
    "        plt.fill_between(timepoints, y-yerr, y+yerr,\n",
    "                        alpha=0.2, edgecolor=None, facecolor=linex[0].get_color())\n",
    "\n",
    "    ax.set_ylim([0.4,1.0])\n",
    "    ax.axvline(0,color='k')\n",
    "    ax.axhline(0.5,color='k',linewidth=0.5,linestyle='--')\n",
    "    ax.set_title(session.metadata['mouseID']+' session '+str(session.metadata['ephys_session_num'])+\n",
    "                '; n_units='+str(u_num)+'; n_trials='+str(trnum)+'; n_repeats='+str(n_repeats)+' shuffled')\n",
    "    ax.legend(plot_results.keys(),ncol=3)\n",
    "    ax.set_ylabel('decodability of context')\n",
    "    ax.set_xlabel('time from stimulus onset (s)')\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    figpath=r\"C:\\Users\\ethan.mcbride\\OneDrive - Allen Institute\\quick figures\\2023-04-04-DR_SAC_decoding_context\"\n",
    "\n",
    "    figname=(session.metadata['mouseID']+'_session_'+str(session.metadata['ephys_session_num'])+\n",
    "                '_n_units_'+str(u_num)+'_n_trials_'+str(trnum)+'_n_repeats_'+str(n_repeats)+'_shuffled.png')\n",
    "    # figname='control_heatmap_500ms_all.png'\n",
    "    plt.savefig(os.path.join(figpath,figname), dpi=600, facecolor='w', edgecolor='w',\n",
    "                orientation='portrait', format='png',\n",
    "                transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "                metadata=None)\n",
    "    \n",
    "    print(path+' done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba28c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_inds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3d8db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27d2dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.good_units.query('area_short==@aa').index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6519f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.good_units['area_short'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae38f5fb",
   "metadata": {},
   "source": [
    "## loop through experiments & save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84c76e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trnum='all'\n",
    "u_num='all'\n",
    "u_min=20\n",
    "n_repeats=100\n",
    "binsize=0.1\n",
    "time_bins=np.arange(-0.2,0.6,binsize)\n",
    "        \n",
    "svc_results={}\n",
    "\n",
    "for sel_session, path in enumerate(main_path):\n",
    "    \n",
    "    svc_results[sel_session]={}\n",
    "    \n",
    "    session=[]\n",
    "    session=Session(path=path) \n",
    "    session.assign_unit_areas()\n",
    "    session=compute_smoothed_response_rate(session)\n",
    "    \n",
    "    # loop through sessions and make unit xarrays\n",
    "    time_before_flash = 0.25\n",
    "    trial_duration = 1.0\n",
    "    bin_size = 0.001\n",
    "\n",
    "    # Make tensor (3-D matrix [units,time,trials])\n",
    "    trial_tensor = make_neuron_time_trials_tensor(session.good_units, session.spike_times, \n",
    "                                                  session.trials,time_before_flash, trial_duration, \n",
    "                                                  bin_size)\n",
    "    # make xarray\n",
    "    session.trial_da = xr.DataArray(trial_tensor, dims=(\"unit_id\", \"time\", \"trials\"), \n",
    "                               coords={\n",
    "                                   \"unit_id\": session.good_units.index.values,\n",
    "                                   \"time\": np.arange(0, trial_duration, bin_size)-time_before_flash,\n",
    "                                   \"trials\": session.trials.index.values\n",
    "                                   })\n",
    "    \n",
    "    #shorten the area names to better lump together units\n",
    "    #get rig of layers and/or sub-areas with dashes\n",
    "    area_short = []\n",
    "    for area in session.good_units['area']:\n",
    "        if area=='N/A':\n",
    "            short='N/A'\n",
    "        elif area[:2]=='CA':\n",
    "            short=area\n",
    "        else:\n",
    "            dig_ind=re.search(r\"\\d\", area)\n",
    "            dash_ind=re.search(r\"-\", area)\n",
    "            if dig_ind!=None:\n",
    "                short=area[:dig_ind.start()]\n",
    "            elif dash_ind!=None:\n",
    "                short=area[:dash_ind.start()]\n",
    "            else:\n",
    "                short=area\n",
    "        area_short.append(short)\n",
    "    session.good_units['area_short']=area_short\n",
    "    area_counts=session.good_units['area_short'].value_counts()\n",
    "\n",
    "    # grab data: make these [trials,neurons] matrices based on different time bins:\n",
    "\n",
    "#     hit_trials = session.trials.query(\n",
    "#         '(trialStimID == \"vis1\" and \\\n",
    "#         trialstimRewarded == \"vis1\" and \\\n",
    "#         trial_response == True and \\\n",
    "#         vis_autoreward_trials == False and \\ \n",
    "#         aud_autoreward_trials == False and \\\n",
    "#         cross_modal_dprime >= 1.5 or \\\n",
    "#         (trialStimID == \"sound1\" and \\\n",
    "#         trialstimRewarded == \"sound1\" and \\\n",
    "#         trial_response == True and \\\n",
    "#         vis_autoreward_trials == False and \\ \n",
    "#         aud_autoreward_trials == False and \\\n",
    "#         cross_modal_dprime >= 1.5').index\n",
    "\n",
    "#     cr_trials = session.trials.query(\n",
    "#         '(trialStimID == \"vis1\" and \\\n",
    "#         trialstimRewarded == \"sound1\" and \\\n",
    "#         trial_response == False and \\\n",
    "#         vis_autoreward_trials == False and \\ \n",
    "#         aud_autoreward_trials == False and \\\n",
    "#         cross_modal_dprime >= 1.5 or \\\n",
    "#         (trialStimID == \"sound1\" and \\\n",
    "#         trialstimRewarded == \"vis1\" and \\\n",
    "#         trial_response == False and \\\n",
    "#         vis_autoreward_trials == False and \\ \n",
    "#         aud_autoreward_trials == False and \\\n",
    "#         cross_modal_dprime >= 1.5').index\n",
    "\n",
    "    \n",
    "#     trial_sel=np.sort(np.hstack([hit_trials,cr_trials]))\n",
    "    \n",
    "    if 'trialOptoVoltage' in session.trials.columns:\n",
    "        trial_sel = session.trials.query('vis_autoreward_trials == False and \\\n",
    "                                          aud_autoreward_trials == False and \\\n",
    "                                          cross_modal_dprime >= 1.5 and \\\n",
    "                                          trialStimID != \"catch\" and \\\n",
    "                                          trialOptoVoltage.isnull()').index\n",
    "    else:\n",
    "        trial_sel = session.trials.query('vis_autoreward_trials == False and \\\n",
    "                                          aud_autoreward_trials == False and \\\n",
    "                                          cross_modal_dprime >= 1.5 and \\\n",
    "                                          trialStimID != \"catch\"').index\n",
    "        \n",
    "    predict=['stim_ids','block_ids','trial_response']\n",
    "\n",
    "    # grab the stimulus ids\n",
    "    stim_ids = session.trials['trialStimID'][trial_sel].values\n",
    "    # or, use block IDs\n",
    "    block_ids = session.trials['trialstimRewarded'][trial_sel].values\n",
    "    #or, use whether mouse responded\n",
    "    trial_response = session.trials['trial_response'][trial_sel].values\n",
    "      \n",
    "    for p in predict:\n",
    "        svc_results[sel_session][p]={}\n",
    "    \n",
    "        #choose what variable to predict\n",
    "        if p=='stim_ids':\n",
    "            pred_var = stim_ids\n",
    "        elif p=='block_ids':\n",
    "            pred_var = block_ids\n",
    "        elif p=='trial_response':\n",
    "            pred_var = trial_response\n",
    "\n",
    "        area_sel = area_counts[area_counts>=u_min].index\n",
    "        # area_sel = ['all']\n",
    "\n",
    "        for aa in area_sel:\n",
    "            if aa=='all':\n",
    "                unit_sel = session.good_units.index.values\n",
    "            else:\n",
    "                unit_sel = session.good_units.query('area_short==@aa').index.values\n",
    "            svc_results[sel_session][p][aa]={}\n",
    "\n",
    "            for tt,t_start in enumerate(time_bins[:-1]):\n",
    "                svc_results[sel_session][p][aa][tt]={}\n",
    "\n",
    "                for nn in range(0,n_repeats):\n",
    "                    if u_num=='all':\n",
    "                        unit_subset = np.random.choice(unit_sel,len(unit_sel),replace=True)\n",
    "                    else:\n",
    "                        unit_subset = np.random.choice(unit_sel,u_num,replace=True)\n",
    "                        \n",
    "                    ### make sure equal # of trials per condition!\n",
    "                    subset_ind=[]\n",
    "                    conds = np.unique(pred_var)\n",
    "                    cond_count=[]\n",
    "                    \n",
    "                    if trnum=='all':\n",
    "                        for cc in conds:\n",
    "                            cond_count.append(np.sum(pred_var==cc))\n",
    "                        use_trnum=np.min(cond_count)\n",
    "                    else:\n",
    "                        use_trnum = trnum\n",
    "                    \n",
    "                    for cc in conds:\n",
    "                        cond_inds=np.where(pred_var==cc)[0]\n",
    "                        if len(cond_inds)<use_trnum:\n",
    "                            use_trnum=len(cond_inds)\n",
    "                        subset_ind.append(np.random.choice(cond_inds,use_trnum,replace=False))   \n",
    "                    subset_ind=np.sort(np.hstack(subset_ind))\n",
    "\n",
    "                    sel_data = session.trial_da.sel(time=slice(t_start,time_bins[tt+1]),\n",
    "                                                    trials=trial_sel[subset_ind],\n",
    "                                                    unit_id=unit_subset).mean(dim='time').values\n",
    "\n",
    "#                     X = sel_data.T\n",
    "                    scaler = StandardScaler()\n",
    "                    scaler.fit(sel_data.T)\n",
    "                    X = scaler.transform(sel_data.T)\n",
    "                    y = pred_var[subset_ind].flatten()\n",
    "\n",
    "                    xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "                    clf = svm.LinearSVC()\n",
    "                    clf.fit(xtrain, ytrain)\n",
    "\n",
    "                    ypred = clf.predict(xtest)\n",
    "\n",
    "                    cr_dict=classification_report(ytest, ypred, output_dict=True)\n",
    "                    cr_df=pd.DataFrame.from_dict(cr_dict)\n",
    "\n",
    "                    svc_results[sel_session][p][aa][tt][nn]=cr_df\n",
    "\n",
    "            print(aa+' done')\n",
    "\n",
    "            \n",
    "savepath=r'C:\\Users\\ethan.mcbride\\OneDrive - Allen Institute\\DR decoding results'\n",
    "\n",
    "with open(os.path.join(savepath,'decoder_results_100ms_incl_all_trials.pkl'), 'wb') as handle:\n",
    "    pickle.dump(svc_results, handle, protocol=pickle.HIGHEST_PROTOCOL)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d464f6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc_results[0]['block_ids'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b1a3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc_results[5]['block_ids']['MOs'][0][0]['vis1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a1caab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# u_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc90bea0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make into more plottable format\n",
    "\n",
    "####change this to deal with multiple #s of trials and average over re-runs of the SVC\n",
    "\n",
    "plot_results={}\n",
    "\n",
    "timepoints=time_bins[1:]\n",
    "\n",
    "label_list=['vis1','vis2','sound1','sound2','True','False']\n",
    "# label_list=['vis1','sound1','True','False']\n",
    "\n",
    "predict=['stim_ids','block_ids','trial_response']\n",
    "\n",
    "areas=['VISp','AUD','MOs','MRN','CP']\n",
    "\n",
    "for sel_session, path in enumerate(main_path):\n",
    "    plot_results[sel_session]={}\n",
    "    for aa in areas:\n",
    "        plot_results[sel_session][aa]={}\n",
    "        for p in predict:\n",
    "            plot_results[sel_session][aa][p]={}\n",
    "            for ll in label_list:\n",
    "                plot_results[sel_session][aa][p][ll]=np.zeros((len(timepoints),n_repeats))\n",
    "                plot_results[sel_session][aa][p][ll][:]=np.nan\n",
    "\n",
    "    \n",
    "# diff table for each timepoint?\n",
    "# row = session\n",
    "# columns = ['modality','A_vis','A_aud','B_vis','B_aud','C_vis','C_aud','F_vis','F_aud',]\n",
    "\n",
    "decoder_acc_session_mean = {}\n",
    "for aa in areas:\n",
    "    decoder_acc_session_mean[aa]={}\n",
    "    for p in predict:\n",
    "        decoder_acc_session_mean[aa][p]={}\n",
    "        for ll in label_list:\n",
    "            \n",
    "            decoder_acc_session_mean[aa][p][ll]=np.zeros((len(timepoints),\n",
    "                                                           len(main_path)))\n",
    "            decoder_acc_session_mean[aa][p][ll][:]=np.nan\n",
    "        \n",
    "\n",
    "for sel_session, path in enumerate(main_path):\n",
    "    for p in predict:\n",
    "        for aa in areas: \n",
    "            if aa in svc_results[sel_session][p].keys():\n",
    "                for tt,tp in enumerate(timepoints):\n",
    "                    for nn in range(0,n_repeats):\n",
    "                        for ll in label_list:\n",
    "                            if len(svc_results[sel_session][p][aa])>0:\n",
    "                                if len(svc_results[sel_session][p][aa][tt])>0:\n",
    "                                    if ll in svc_results[sel_session][p][aa][tt][nn].keys():\n",
    "                                        temp_perf=np.nanmean(svc_results[sel_session][p]\n",
    "                                                          [aa][tt][nn][ll]\n",
    "                                                          [['precision','recall']].values)\n",
    "                                        plot_results[sel_session][aa][p][ll][tt,nn]=temp_perf\n",
    "\n",
    "                    for ll in label_list:\n",
    "                        if len(svc_results[sel_session][p][aa])>0:                    \n",
    "#                             concat_results = np.concatenate((plot_results[sel_session][aa][p][ll][tt],\n",
    "#                                                              plot_results[sel_session][aa][p][ll][tt]),\n",
    "#                                                             axis=2)\n",
    "#                             decoder_acc_mean = np.nanmean(concat_results,2)\n",
    "                            decoder_acc_mean = np.nanmean(plot_results[sel_session][aa][p][ll][tt])\n",
    "                            decoder_acc_session_mean[aa][p][ll][tt,sel_session] = decoder_acc_mean\n",
    "    \n",
    "    \n",
    "# plot_results[area][label/stimulus][timepoint_idx][ntrials_idx,nunits_idx,n_repeats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09bc0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_results[sel_session][aa][p][ll][tt]\n",
    "plot_results[sel_session].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9044ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(decoder_acc_session_mean['VISp']['block_ids']['vis1'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aded48",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_var='block_ids'\n",
    "sel_stim='sound1'\n",
    "\n",
    "fig,ax=plt.subplots(1,1)\n",
    "\n",
    "ax.axvline(0,color='k',linestyle='--',linewidth=1)\n",
    "ax.axhline(0.5,color='k',linestyle='--',linewidth=1)\n",
    "\n",
    "ax.plot(time_bins[1:],decoder_acc_session_mean['VISp'][predict_var][sel_stim],'k',linewidth=0.75,alpha=0.5)\n",
    "# ax.plot(time_bins[1:],decoder_acc_session_mean['AUDp'][predict_var][sel_stim],'m',linewidth=0.75,alpha=0.5)\n",
    "ax.plot(time_bins[1:],decoder_acc_session_mean['MOs'][predict_var][sel_stim],'b',linewidth=0.75,alpha=0.5)\n",
    "# ax.plot(time_bins[1:],decoder_acc_session_mean['MRN'][predict_var][sel_stim],'r',linewidth=0.75,alpha=0.5)\n",
    "# ax.plot(time_bins[1:],decoder_acc_session_mean['CP'][predict_var][sel_stim],'g',linewidth=0.75,alpha=0.5)\n",
    "\n",
    "\n",
    "visp_line=ax.plot(time_bins[1:],np.nanmean(decoder_acc_session_mean['VISp'][predict_var][sel_stim],axis=1)\n",
    "        ,'k.-',linewidth=2)\n",
    "# ax.plot(time_bins[1:],np.nanmean(decoder_acc_session_mean['AUDp'][predict_var][sel_stim],axis=1)\n",
    "#         ,'m.-',linewidth=2)\n",
    "mos_line=ax.plot(time_bins[1:],np.nanmean(decoder_acc_session_mean['MOs'][predict_var][sel_stim],axis=1)\n",
    "        ,'b.-',linewidth=2)\n",
    "# ax.plot(time_bins[1:],np.nanmean(decoder_acc_session_mean['MRN'][predict_var][sel_stim],axis=1)\n",
    "#         ,'r.-',linewidth=2)\n",
    "# ax.plot(time_bins[1:],np.nanmean(decoder_acc_session_mean['CP'][predict_var][sel_stim],axis=1)\n",
    "#         ,'g.-',linewidth=2)\n",
    "\n",
    "\n",
    "ax.set_ylim([0.4,1.0])\n",
    "ax.set_xlabel('time relative to stim onset (s)')\n",
    "ax.set_ylabel('block decoding accuracy')\n",
    "ax.set_title('decode: '+sel_stim)\n",
    "ax.legend([visp_line[0],mos_line[0]],['VISp','MOs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23920ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_acc_session_mean['AUD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1803ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_var='block_ids'\n",
    "sel_stim='vis1'\n",
    "st.ranksums(decoder_acc_session_mean['VISp'][predict_var][sel_stim][0,:],\n",
    "            decoder_acc_session_mean['MOs'][predict_var][sel_stim][0,:],\n",
    "            nan_policy='omit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8178a0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(~np.isnan(decoder_acc_session_mean['MOs'][predict_var][sel_stim][0,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b0b6d9",
   "metadata": {},
   "source": [
    "## loop through experiments, save all relevant info (plot later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2933bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_decoder(input_data,labels):\n",
    "    \n",
    "    output={}\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    skf = StratifiedKFold(n_splits=5,shuffle=True)\n",
    "    \n",
    "    scaler.fit(sel_data.T)\n",
    "    X = scaler.transform(input_data)\n",
    "    y = labels\n",
    " \n",
    "    if type(y[0])==bool:\n",
    "        ypred=np.full(len(y), fill_value=False)\n",
    "    elif type(y[0])==str:\n",
    "        ypred=np.full(len(y), fill_value='       ')\n",
    "    else:\n",
    "        ypred=np.full(len(y), fill_value=np.nan)\n",
    "\n",
    "    tidx_used=[]\n",
    "\n",
    "    for train,test in skf.split(X, y):\n",
    "        clf=svm.LinearSVC()\n",
    "        clf.fit(X[train],y[train])\n",
    "        ypred[test] = clf.predict(X[test])\n",
    "        tidx_used.append([test])\n",
    "\n",
    "    cr_dict=classification_report(y, ypred, output_dict=True)\n",
    "    cr_df=pd.DataFrame.from_dict(cr_dict)\n",
    "\n",
    "    output['cr']=cr_df\n",
    "    output['pred_label']=ypred\n",
    "    output['true_label']=y\n",
    "    output['trials_used']=tidx_used\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1820ccf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trnum='all'\n",
    "u_num='all'\n",
    "u_min=20\n",
    "n_repeats=100\n",
    "binsize=0.1\n",
    "time_bins=np.arange(-0.5,1.0,binsize)\n",
    "balance_labels=0\n",
    "\n",
    "svc_results={}\n",
    "\n",
    "for sel_session, path in enumerate(main_path):\n",
    "    \n",
    "    svc_results[sel_session]={}\n",
    "    \n",
    "    session=[]\n",
    "    session=Session(path=path) \n",
    "    session.assign_unit_areas()\n",
    "    session=compute_smoothed_response_rate(session)\n",
    "    \n",
    "    # loop through sessions and make unit xarrays\n",
    "    time_before_flash = 0.5\n",
    "    trial_duration = 1.5\n",
    "    bin_size = 0.001\n",
    "\n",
    "    # Make tensor (3-D matrix [units,time,trials])\n",
    "    trial_tensor = make_neuron_time_trials_tensor(session.good_units, session.spike_times, \n",
    "                                                  session.trials,time_before_flash, trial_duration, \n",
    "                                                  bin_size)\n",
    "    # make xarray\n",
    "    session.trial_da = xr.DataArray(trial_tensor, dims=(\"unit_id\", \"time\", \"trials\"), \n",
    "                               coords={\n",
    "                                   \"unit_id\": session.good_units.index.values,\n",
    "                                   \"time\": np.arange(0, trial_duration, bin_size)-time_before_flash,\n",
    "                                   \"trials\": session.trials.index.values\n",
    "                                   })\n",
    "    \n",
    "    #shorten the area names to better lump together units\n",
    "    #get rid of layers and/or sub-areas with dashes\n",
    "    area_short = []\n",
    "    for area in session.good_units['area']:\n",
    "        if area=='N/A':\n",
    "            short='N/A'\n",
    "        elif area[:2]=='CA':\n",
    "            short=area\n",
    "        else:\n",
    "            dig_ind=re.search(r\"\\d\", area)\n",
    "            dash_ind=re.search(r\"-\", area)\n",
    "            if dig_ind!=None:\n",
    "                short=area[:dig_ind.start()]\n",
    "            elif dash_ind!=None:\n",
    "                short=area[:dash_ind.start()]\n",
    "            else:\n",
    "                short=area\n",
    "        area_short.append(short)\n",
    "    session.good_units['area_short']=area_short\n",
    "    area_counts=session.good_units['area_short'].value_counts()\n",
    "\n",
    "    #exclude any trials that had opto stimulation\n",
    "    if 'trialOptoVoltage' in session.trials.columns:\n",
    "        trial_sel = session.trials.query('trialOptoVoltage.isnull()').index\n",
    "    else:\n",
    "        trial_sel = session.trials.index\n",
    "\n",
    "    predict=['stim_ids','block_ids','trial_response']\n",
    "\n",
    "    # grab the stimulus ids\n",
    "    stim_ids = session.trials['trialStimID'][trial_sel].values\n",
    "    # or, use block IDs\n",
    "    block_ids = session.trials['trialstimRewarded'][trial_sel].values\n",
    "    #or, use whether mouse responded\n",
    "    trial_response = session.trials['trial_response'][trial_sel].values\n",
    "    \n",
    "    #save metadata about this session & decoder params\n",
    "    svc_results[sel_session]['metadata']=session.metadata\n",
    "    svc_results[sel_session]['trial_numbers']=trnum\n",
    "    svc_results[sel_session]['unit_numbers']=u_num\n",
    "    svc_results[sel_session]['min_n_units']=u_min\n",
    "    svc_results[sel_session]['n_repeats']=n_repeats\n",
    "    svc_results[sel_session]['time_bins']=time_bins\n",
    "    svc_results[sel_session]['balance_labels']=balance_labels\n",
    "    \n",
    "    #loop through different labels to predict\n",
    "    for p in predict:\n",
    "        svc_results[sel_session][p]={}\n",
    "    \n",
    "        #choose what variable to predict\n",
    "        if p=='stim_ids':\n",
    "            pred_var = stim_ids\n",
    "        elif p=='block_ids':\n",
    "            pred_var = block_ids\n",
    "        elif p=='trial_response':\n",
    "            pred_var = trial_response\n",
    "\n",
    "        area_sel = area_counts[area_counts>=u_min].index\n",
    "        # area_sel = ['all']\n",
    "        \n",
    "        #loop through areas\n",
    "        for aa in area_sel:\n",
    "            if aa=='all':\n",
    "                unit_sel = session.good_units.index.values\n",
    "            else:\n",
    "                unit_sel = session.good_units.query('area_short==@aa').index.values\n",
    "            svc_results[sel_session][p][aa]={}\n",
    "            svc_results[sel_session][p][aa]['n_units']=len(unit_sel)\n",
    "            \n",
    "            #loop through time bins\n",
    "            for tt,t_start in enumerate(time_bins[:-1]):\n",
    "                svc_results[sel_session][p][aa][tt]={}\n",
    "                \n",
    "                #loop through repeats\n",
    "                for nn in range(0,n_repeats):\n",
    "                    \n",
    "                    if u_num=='all':\n",
    "                        unit_subset = np.random.choice(unit_sel,len(unit_sel),replace=False)\n",
    "                    else:\n",
    "                        unit_subset = np.random.choice(unit_sel,u_num,replace=False)\n",
    "                    \n",
    "                    #option to balance number of labels for training\n",
    "                    if balance_labels:\n",
    "                        subset_ind=[]\n",
    "                        conds = np.unique(pred_var)\n",
    "                        cond_count=[]\n",
    "\n",
    "                        if trnum=='all':\n",
    "                            for cc in conds:\n",
    "                                cond_count.append(np.sum(pred_var==cc))\n",
    "                            use_trnum=np.min(cond_count)\n",
    "                        else:\n",
    "                            use_trnum = trnum\n",
    "\n",
    "                        for cc in conds:\n",
    "                            cond_inds=np.where(pred_var==cc)[0]\n",
    "                            if len(cond_inds)<use_trnum:\n",
    "                                use_trnum=len(cond_inds)\n",
    "                            subset_ind.append(np.random.choice(cond_inds,use_trnum,replace=False))   \n",
    "                        subset_ind=np.sort(np.hstack(subset_ind))\n",
    "\n",
    "                        trial_sel=trial_sel[subset_ind]\n",
    "                        pred_var=pred_var[subset_ind]\n",
    "\n",
    "\n",
    "                    sel_data = session.trial_da.sel(time=slice(t_start,time_bins[tt+1]),\n",
    "                                                    trials=trial_sel,\n",
    "                                                    unit_id=unit_subset).mean(dim='time').values\n",
    "\n",
    "                    svc_results[sel_session][p][aa][tt][nn]=custom_decoder(\n",
    "                        input_data=sel_data.T,\n",
    "                        labels=pred_var.flatten())\n",
    "\n",
    "                    svc_results[sel_session][p][aa][tt][nn]['shuffle']=custom_decoder(\n",
    "                        input_data=sel_data.T,\n",
    "                        labels=np.random.choice(pred_var,len(pred_var),replace=False).flatten())\n",
    "\n",
    "                    svc_results[sel_session][p][aa][tt][nn]['trial_sel_idx']=trial_sel\n",
    "                    \n",
    "\n",
    "            print(aa+' done')\n",
    "            \n",
    "    print(path+' done')\n",
    "            \n",
    "savepath=r'C:\\Users\\ethan.mcbride\\OneDrive - Allen Institute\\DR decoding results'\n",
    "\n",
    "with open(os.path.join(savepath,'decoder_results_100ms_incl_all_units_trials_metadata.pkl'), 'wb') as handle:\n",
    "    pickle.dump(svc_results, handle, protocol=pickle.HIGHEST_PROTOCOL)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d23e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eafede8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3946f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:allensdk_38_new]",
   "language": "python",
   "name": "conda-env-allensdk_38_new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
